\part{Discrete Distributions}\label{discrete-prob-functions.part}

\chapter{Conventions for Probability Functions}

Functions associated with distributions are set up to follow the same
naming conventions for both built-in distributions and for user-defined
distributions. 

\section{Suffix Marks Type of Function}

The suffix is determined by the type of function according to the
following table.
%
\begin{center}
\begin{tabular}{cc|c}
{\it function} & {\it outcome} & {\it suffix} \\ \hline
log probability mass function  & discrete & \code{\_lpmf} \\
log probability density function  & continuous & \code{\_lpdf} \\
\hline
log cumulative distribution function & any & \code{\_lcdf} \\
log complementary cumulative distribution function & any & \code{\_lccdf} \\ 
\hline
random number generator & any & \code{\_rng}
\end{tabular}
\end{center}
%
For example, \code{normal\_lpdf} is the log of the normal probability
density function (pdf) and \code{bernoulli\_lpmf} is the log of the
bernoulli probability mass function (pmf).  The log of the corresponding
cumulative distribution functions (cdf) use the same suffix,
\code{normal\_lcdf} and \code{bernoulli\_lcdf}.

\section{Argument Order and the Vertical Bar}

Each probability function has a specific outcome value and a number of
parameters.  Following conditional probability notation, probability
density and mass functions use a vertical bar to separate the outcome
from the parameters of the distribution.  For example,
\code{normal\_lpdf(y | mu, sigma)} returns the value of
mathematical formula $log \distro{Normal}(y \, | \, \mu, \sigma)$.
Cumulative distribution functions separate the outcome from the
parameters in the same way (e.g., \code{normal\_lcdf(y\_low | mu, sigma)}

\section{Sampling Notation}

The notation
%
\begin{stancode}
y ~ normal(mu, sigma);
\end{stancode}
%
provides the same (proportional) contribution to the model log density
as the explicit target density increment,
%
\begin{stancode}
target += normal_lpdf(y | mu, sigma);
\end{stancode}
%
In both cases, the effect is to add terms to the target log density.
The only difference is that the example with the sampling (\Verb|~|)
notation drops all additive constants in the log density;  the
constants are not necessary for any of Stan's sampling, approximation,
or optimization algorithms.

\section{Finite Inputs}

All of the distribution functions are configured to throw exceptions
(effectively rejecting samples or optimization steps) when they are
supplied with non-finite arguments.  The two cases of non-finite
arguments are the infinite values and not-a-number value;  see
\refsection{numerical-data-types} for more information on
floating-point values.


\section{Boundary Conditions}

Many distributions are defined with support or constraints on
parameters forming an open interval.  For example, the normal density
function accepts a scale parameter $\sigma > 0$.  If $\sigma = 0$, the
probability function will throw an exception.

This is true even for (complementary) cumulative distribution
functions, which will throw exceptions when given input that is out of
the support.

\section{Pseudorandom Number Generators}\label{distributions-prng.section}

For most of the probability functions, there is a matching
pseudorandom number generator (PRNG) with the suffix \code{\_rng}.
For example, the function \code{normal\_rng(real, real)} accepts two
real arguments, an unconstrained location $\mu$ and positive scale
$\sigma > 0$, and returns an unconstrained pseudorandom value drawn
from $\distro{Normal}(\mu,\sigma)$.

\subsection{Generated Quantities Only}

Unlike regular functions, the PRNG functions may only be used in the
generated quantities block.

\subsection{Not Vectorized}

Unlike the probability functions, the PRNG functions are not
vectorized.


\section{Cumulative Distribution Functions}

For most of the univariate probability functions, there is a
corresponding cumulative distribution function, log cumulative
distribution function, and log complementary cumulative distribution
function.

For a univariate random variable $Y$ with probability function $p_Y(y \,
| \, \theta)$, the cumulative distribution function (CDF) $F_Y$ is
defined by
\[
F_Y(y) 
\ = \
\mbox{Pr}[Y < y] 
\ = \
\int_{-\infty}^y p(y \, | \, \theta) \ \mathrm{d}\theta.
\]
The complementary cumulative distribution function (CCDF) is defined
as 
\[
\mbox{Pr}[Y \geq y]
\ = \
1 - F_Y(y).
\]
The reason to use CCDFs instead of CDFs in floating-point arithmetic
is that it is possible to represent numbers very close to 0 (the
closest you can get is roughly $10^{-300}$), but not numbers very close
to 1 (the closest you can get is roughly $1 - 10^{-15}$).

In Stan, there is a cumulative distribution function for each
probability function.  For instance, \code{normal\_cdf(y,~mu,~sigma)}
is defined by 
%
\[
\int_0^y \distro{Normal}(y \, | \, \mu, \sigma) \ \mathrm{d}y.
\]
%
There are also log forms of the CDF and CCDF for most univariate
distributions.  For example, \code{normal\_lcdf(y~|~mu,~sigma)} is
defined by
%
\[
\log \left( \int_0^y \distro{Normal}(y \, | \, \mu, \sigma) \
  \mathrm{d}y \right)
\]
%
and \code{normal\_lccdf(y | mu,~sigma)} is defined by
%
\[
\log \left( 1 - \int_0^y \distro{Normal}(y \, | \, \mu, \sigma) \
  \mathrm{d}y \right).
\]


\section{Vectorization}\label{vectorization.section}

\noindent
Stan's univariate log probability functions, including the log density
functions, log mass functions, log CDFs, and log CCDFs, all support vectorized
function application, with results defined to be the sum of the
elementwise application of the function.

In all cases, matrix operations are at least as fast and usually
faster than loops and vectorized log probability functions are faster
than their equivalent form defined with loops.  This isn't because
loops are slow in Stan, but because more efficient automatic
differentiation can be used.  The efficiency comes from the fact that
a vectorized log probably function only introduces one new node into
the expression graph, thus reducing the number of virtual function
calls required to compute gradients in \Cpp, as well as from allowing
caching of repeated computations.

Stan also overloads the multivariate normal distribution, including
the Cholesky-factor form, allowing arrays of row vectors or vectors
for the variate and location parameter.  This is a huge savings in
speed because the work required to solve the linear system for the
covariance matrix is only done once.

Stan also overloads some scalar functions, such as \code{log} and
\code{exp}, to apply to vectors (arrays) and return vectors (arrays).  
These vectorizations are defined elementwise and unlike the
probability functions, provide only minimal efficiency speedups over
repeated application and assignment in a loop.


\subsection{Vectorized Function Signatures}\label{prob-vectorization.section}

\subsubsection{Vectorized Scalar Arguments}

The normal probability function is specified with the signature
%
\begin{stancode}
normal_lpdf(reals | reals, reals);
\end{stancode}
%
The pseudo-type \code{reals} is used to indicate that an argument
position may be vectorized.  Argument positions declared as
\code{reals} may be filled with a real, a one-dimensional array, a
vector, or a row-vector.  If there is more than one array or vector
argument, their types can be anything but their size must match.  For
instance, it is legal to use
\code{normal\_lpdf(row\_vector~|~vector,~real)} as long as the vector and
row vector have the same size.  

\subsubsection{Vectorized Vector and Row Vector Arguments}

The multivariate normal distribution accepting vector or array of
vector arguments is written as
%
\begin{stancode}
multi_normal_lpdf(vectors | vectors, matrix);
\end{stancode}
%
These arguments may be row vectors, column vectors, or arrays of row
vectors or column vectors.

\subsubsection{Vectorized Integer Arguments}

The pseudo-type \code{ints} is used for vectorized integer arguments.
Where it appears either an integer or array of integers may be used.


\subsection{Evaluating Vectorized Functions}

The result of a vectorized log probability function is equivalent to
the sum of the evaluations on each element.  Any non-vector argument,
namely \code{real} or \code{int}, is repeated.  For instance, if
\code{y} is a vector of size \code{N}, \code{mu} is a vector of size
\code{N}, and \code{sigma} is a scalar, then
%
\begin{stancode}
ll = normal_lpdf(y | mu, sigma);
\end{stancode}
%
is just a more efficient way to write
%
\begin{stancode}
ll = 0;
for (n in 1:N)
  ll = ll + normal_lpdf(y[n] | mu[n], sigma);
\end{stancode}
%
With the same arguments, the vectorized sampling statement
%
\begin{stancode}
y ~ normal(mu, sigma);
\end{stancode}
%
has the same effect on the total log probability as
%
\begin{stancode}
for (n in 1:N)
  y[n] ~ normal(mu[n], sigma);
\end{stancode}



\chapter{Binary Distributions}

\noindent
Binary probability distributions have support on $\setlist{0,1}$,
where 1 represents the value true and 0 the value false.

\section{Bernoulli Distribution}

\subsubsection{Probability Mass Function}

If $\theta \in [0,1]$, then for $y \in \setlist{0,1}$,
\[
\distro{Bernoulli}(y|\theta)
=
\left\{
\begin{array}{ll}
\theta & \mbox{if } y = 1, \mbox{ and}
\\
1 - \theta & \mbox{if } y = 0.
\end{array}
\right.
\]

\pitemdisc{y}{bernoulli}{theta}

\subsubsection{Stan Functions}

\begin{description}
%
\fitem{real}{bernoulli\_lpmf}{ints \farg{y} \textbar\ reals \farg{theta}}{The
  log Bernoulli probability mass of \farg{y} given chance of success
  \farg{theta}}

%

\end{description}

\begin{description}
%
\fitem{real}{bernoulli\_cdf}{ints \farg{y}, reals \farg{theta}}{The
  Bernoulli cumulative distribution function of \farg{y} given chance of success
  \farg{theta}}
%
\fitem{real}{bernoulli\_lcdf}{ints \farg{y} \textbar\ reals \farg{theta}}{The
  log of the Bernoulli cumulative distribution function of \farg{y} given
  chance of success \farg{theta}}
%
\fitem{real}{bernoulli\_lccdf}{ints \farg{y} \textbar\ reals \farg{theta}}{The
  log of the Bernoulli complementary cumulative distribution function of
  \farg{y} given chance of success \farg{theta}}
\end{description}
%
\begin{description}
\fitem{int}{bernoulli\_rng}{real \farg{theta}}{Generate a Bernoulli
  variate with chance of success \farg{theta}; may only be used in
  generated quantities block}
\end{description}

\section{Bernoulli Distribution, Logit Parameterization}\label{bernoulli-logit-distribution.section}

Stan also supplies a direct parameterization in terms of a
logit-transformed chance-of-success parameter.  This parameterization
is more numerically stable if the chance-of-success parameter is on
the logit scale, as with the linear predictor in a logistic
regression.

\subsubsection{Probability Mass Function}

If $\alpha \in \reals$, then for $c \in \setlist{0,1}$,
\[
\distro{BernoulliLogit}(c|\alpha)
=
\distro{Bernoulli}(c|\mbox{logit}^{-1}(\alpha))
=
\left\{
\begin{array}{ll}
\mbox{logit}^{-1}(\alpha) & \mbox{if } y = 1, \mbox{ and}
\\
1 - \mbox{logit}^{-1}(\alpha) & \mbox{if } y = 0.
\end{array}
\right.
\]

\pitemdisc{y}{bernoulli\_logit}{alpha}

\subsubsection{Stan Functions}

\begin{description}
%
\fitem{real}{bernoulli\_logit\_lpmf}{ints \farg{y} \textbar\ reals \farg{alpha}}{The
  log Bernoulli probability mass of \farg{y} given chance of success
  \code{inv\_logit(\farg{alpha})}}
%
\end{description}
%
\begin{description}
\fitem{int}{bernoulli\_logit\_rng}{real \farg{alpha}}{Generate a Bernoulli
  variate with chance of success $\mbox{logit}^{-1}(\alpha)$; may only be used in
  generated quantities block}
\end{description}


\chapter{Bounded Discrete Distributions}\label{betafun.chapter}

\noindent
Bounded discrete probability functions have support on
$\setlist{0,\ldots,N}$ for some upper bound $N$.


\section{Binomial Distribution}

\subsubsection{Probability Mass Function}

Suppose $N \in \nats$ and $\theta \in [0,1]$, and $n \in
\{0,\ldots,N\}$.
\[
\distro{Binomial}(n|N,\theta)
= \binom{N}{n} \theta^n (1 - \theta)^{N - n}.
\]


\subsubsection{Log Probability Mass Function}

\begin{eqnarray*}
\log \distro{Binomial}(n|N,\theta)
& = &
\log \Gamma(N+1) - \log \Gamma(n + 1) - \log \Gamma(N- n + 1)
\\[4pt]
& & { } + n \log \theta + (N - n) \log (1 - \theta),
\end{eqnarray*}


\subsubsection{Gradient of Log Probability Mass Function}

\[
\frac{\partial}{\partial \theta} \log \distro{Binomial}(n|N,\theta)
= \frac{n}{\theta}
- \frac{N - n}{1 - \theta}
\]


\pitemdisc{n}{binomial}{N, theta}

\subsubsection{Stan Functions}

\begin{description}
%
  \fitem{real}{binomial\_lpmf}{ints \farg{n} \textbar\ ints \farg{N}, reals
    \farg{theta}}{The log binomial probability mass of \farg{n}
    successes in \farg{N} trials given chance of success \farg{theta}}
%
  \fitem{real}{binomial\_cdf}{ints \farg{n}, ints \farg{N}, reals
    \farg{theta}}{The binomial cumulative distribution function of \farg{n}
    successes in \farg{N} trials given chance of success \farg{theta}}
%
  \fitem{real}{binomial\_lcdf}{ints \farg{n} \textbar\ ints \farg{N}, reals
    \farg{theta}}{The log of the binomial cumulative distribution function of
    \farg{n} successes in \farg{N} trials given chance of success \farg{theta}}
%
  \fitem{real}{binomial\_lccdf}{ints \farg{n} \textbar\ ints \farg{N}, reals
    \farg{theta}}{The log of the binomial complementary cumulative distribution
     function of \farg{n} successes in \farg{N} trials given chance of success
    \farg{theta}}
%
\end{description}
%
\begin{description}
\fitem{int}{binomial\_rng}{int \farg{N}, real \farg{theta}}{Generate a binomial
  variate with \farg{N} trials and chance of success \farg{theta}; may only be used in
  generated quantities block}
\end{description}



\section{Binomial Distribution, Logit Parameterization}

Stan also provides a version of the binomial probability mass function
distribution with the chance of success parameterized on the
unconstrained logistic scale.

\subsubsection{Probability Mass Function}

Suppose $N \in \nats$, $\alpha \in \reals$, and $n \in
\{0,\ldots,N\}$.

\begin{eqnarray*}
\distro{BinomialLogit}(n|N,\alpha)
& = & \distro{BinomialLogit}(n|N,\mbox{logit}^{-1}(\alpha))
\\[6pt]
& = & \binom{N}{n} \left( \mbox{logit}^{-1}(\alpha) \right)^{n}
                    \left( 1 - \mbox{logit}^{-1}(\alpha) \right)^{N - n}.
\end{eqnarray*}


\subsubsection{Log Probability Mass Function}

\begin{eqnarray*}
\log \distro{BinomialLogit}(n|N,\alpha)
& = &
\log \Gamma(N+1) - \log \Gamma(n + 1) - \log \Gamma(N- n + 1)
\\[4pt]
& & { } + n \log \mbox{logit}^{-1}(\alpha) + (N - n) \log \left( 1 -
  \mbox{logit}^{-1}(\alpha) \right),
\end{eqnarray*}


\subsubsection{Gradient of Log Probability Mass Function}

\[
\frac{\partial}{\partial \alpha} \log \distro{BinomialLogit}(n|N,\alpha)
= \frac{n}{\mbox{logit}^{-1}(-\alpha)}
- \frac{N - n}{\mbox{logit}^{-1}(\alpha)}
\]

\pitemdisc{n}{binomial\_logit}{N, alpha}

\subsubsection{Stan Functions}

\begin{description}
%
  \fitem{real}{binomial\_logit\_lpmf}{ints \farg{n} \textbar\ ints \farg{N}, reals
    \farg{alpha}}{The log binomial probability mass of \farg{n}
    successes in \farg{N} trials given logit-scaled chance of success \farg{alpha}}
%
\end{description}



\section{Beta-Binomial Distribution}

\subsubsection{Probability Mass Function}

If $N \in \nats$, $\alpha \in \posreals$, and $\beta \in \posreals$,
then for $n \in \setlist{0,\ldots,N}$,
\[
\distro{BetaBinomial}(n|N,\alpha,\beta)
=
\binom{N}{n} \frac{\Betafun(n+\alpha, N -n +
  \beta)}{\Betafun(\alpha,\beta)},
\]
%
where the beta function $\Betafun(u,v)$ is defined for $u \in
\posreals$ and $v \in \posreals$ by
%
\[
\Betafun(u,v)
= \frac{\Gamma(u) \ \Gamma(v)}{\Gamma(u + v)}.
\]

\pitemdisc{n}{beta\_binomial}{N, alpha, beta}

\subsubsection{Stan Functions}

\begin{description}
%
\fitem{real}{beta\_binomial\_lpmf}{ints \farg{n} \textbar\ ints \farg{N}, reals
  \farg{alpha}, reals \farg{beta}}{The log beta-binomial probability mass
  of \farg{n} successes in \farg{N} trials given prior success count
  (plus one) of \farg{alpha} and prior failure count (plus one) of
  \farg{beta}}
%
\fitem{real}{beta\_binomial\_cdf}{ints \farg{n}, ints \farg{N}, reals
  \farg{alpha}, reals \farg{beta}}{The beta-binomial cumulative
  distribution function
  of \farg{n} successes in \farg{N} trials given prior success count
  (plus one) of \farg{alpha} and prior failure count (plus one) of
  \farg{beta}}
%
\fitem{real}{beta\_binomial\_lcdf}{ints \farg{n} \textbar\ ints \farg{N}, reals
  \farg{alpha}, reals \farg{beta}}{The log of the beta-binomial cumulative
  distribution function
  of \farg{n} successes in \farg{N} trials given prior success count
  (plus one) of \farg{alpha} and prior failure count (plus one) of
  \farg{beta}}
%
\fitem{real}{beta\_binomial\_lccdf}{ints \farg{n} \textbar\ ints \farg{N}, reals
  \farg{alpha}, reals \farg{beta}}{The log of the beta-binomial complementary
   cumulative distribution function of \farg{n} successes in \farg{N} trials
   given prior success count (plus one) of \farg{alpha} and prior failure count
  (plus one) of \farg{beta}}
\end{description}
%
\begin{description}
\fitem{int}{beta\_binomial\_rng}{int \farg{N}, real \farg{alpha}, real
   \farg{beta}}{Generate a beta-binomial variate with \farg{N} trials, prior
   success count (plus one) of \farg{alpha}, and prior failure count (plus
   one) of \farg{beta}; may only be used in generated quantities block}
\end{description}




\section{Hypergeometric Distribution}

\subsubsection{Probability Mass Function}

If $a \in \nats$, $b \in \nats$, and $N \in \setlist{0,\ldots,a+b}$,
then for $n \in \setlist{\max(0,N-b),\ldots,\min(a,N)}$,
\[
\distro{Hypergeometric}(n|N,a,b)
=
\frac{\normalsize{\binom{a}{n} \binom{b}{N - n}}}
     {\normalsize{\binom{a + b}{N}}}.
\]


\pitemdisc{n}{hypergeometric}{N, a, b}

\subsubsection{Stan Functions}

\begin{description}
%
  \fitem{real}{hypergeometric\_lpmf}{int \farg{n} \textbar\ int \farg{N}, int
    \farg{a}, int \farg{b}}{The log hypergeometric probability mass of
    \farg{n} successes in \farg{N} trials given total success count of
    \farg{a} and total failure count of \farg{b}}

%
\end{description}
%
\begin{description}
\fitem{int}{hypergeometric\_rng}{int \farg{N}, real \farg{a}, real
   \farg{b}}{Generate a hypergeometric variate with \farg{N} trials, total
    success count of \farg{a}, and total failure count of \farg{b}; may only
    be used in generated quantities block}
\end{description}




\section{Categorical Distribution}\label{categorical-distribution.section}

\subsubsection{Probability Mass Functions}

If $N \in \nats$, $N > 0$, and if $\theta \in \reals^N$ forms an
$N$-simplex (i.e., has nonnegative entries summing to one), then for
$y \in \setlist{1,\ldots,N}$,
%
\[
\distro{Categorical}(y|\theta) = \theta_y.
\]
%
In addition, Stan provides a log-odds scaled categorical distribution,
%
\[
\distro{CategoricalLogit}(y|\beta)
= \distro{Categorical}(y|\mbox{softmax}(\beta)).
\]
%
See \refsection{softmax} for the definition of the softmax function.


\pitemdisc{y}{categorical}{theta}
\pitemdisc{y}{categorical\_logit}{beta}


\subsubsection{Stan Functions}

All of the categorical distributions are vectorized so that the
outcome \farg{y} can be a single integer (type \code{int}) or an array
of integers (type \code{int[]}).


\begin{description}
  \fitem{real}{categorical\_lpmf}{ints \farg{y} \textbar\ vector
    \farg{theta}}{The log categorical probability mass function with
    outcome(s) \farg{y} in $1:N$ given $N$-vector of outcome
    probabilities \farg{theta}.  The parameter \farg{theta} must have
    non-negative entries that sum to one, but it need not be a
    variable declared as a simplex.}
%
\fitem{real}{categorical\_logit\_lpmf}{ints \farg{y} \textbar\ vector
  \farg{beta}}{The log categorical probability mass function with
  outcome(s) \farg{y} in $1:N$ given log-odds of outcomes \farg{beta}.}
%
\end{description}
%
\begin{description}
\fitem{int}{categorical\_rng}{vector \farg{theta}}{Generate a
  categorical variate with $N$-simplex distribution parameter
\farg{theta}; may only be used in generated quantities block}
\end{description}



\section{Ordered Logistic Distribution}

\subsubsection{Probability Mass Function}

If $K \in \nats$ with $K > 2$, $c \in \reals^{K-1}$ such that $c_k <
c_{k+1}$ for $k \in \setlist{1,\ldots,K-2}$, and $\eta \in \reals$, then for $k \in
\setlist{1,\ldots,K}$,
\[
\distro{OrderedLogistic}(k|\eta,c)
=
\left\{
\begin{array}{ll}
1 - \mbox{logit}^{-1}(\eta - c_1) & \mbox{if } k = 1,
\\[4pt]
\mbox{logit}^{-1}(\eta - c_{k-1}) - \mbox{logit}^{-1}(\eta -
c_{k})

& \mbox{if } 1 < k < K, \mbox{and}
\\[4pt]
\mbox{logit}^{-1}(\eta - c_{K-1}) - 0
& \mbox{if } k = K.
\end{array}
\right.
\]
%
The $k=K$ case is written with the redundant subtraction of zero to
illustrate the parallelism of the cases; the $k=1$ and $k=K$ edge
cases can be subsumed into the general definition by setting $c_0 =
-\infty$ and $c_K = +\infty$ with $\mbox{logit}^{-1}(-\infty) = 0$ and
$\mbox{logit}^{-1}(\infty) = 1$.

\pitemdisc{k}{ordered\_logistic}{eta, c}


\subsubsection{Stan Functions}

\begin{description}
  \fitem{real}{ordered\_logistic\_lpmf}{int \farg{k} \textbar\ real \farg{eta},
    vector \farg{c}}{The log ordered logistic probability mass of
    \farg{k} given linear predictor \farg{eta} and cutpoints
    \farg{c}.}
%
\fitem{int}{ordered\_logistic\_rng}{real \farg{eta}, vector \farg{c}}{Generate
  an ordered logistic variate with linear predictor \farg{eta} and cutpoints
    \farg{c}; may only be used in generated quantities block}
\end{description}



\chapter{Unbounded Discrete Distributions}

\noindent
The unbounded discrete distributions have support over the natural
numbers (i.e., the non-negative integers).


\section{Negative Binomial Distribution}

For the negative binomial distribution Stan uses the parameterization
described in \citet{GelmanEtAl:2013}.  For alternative parametrizations, see \refsection{nbalt}.

\subsubsection{Probability Mass Function}

If $\alpha \in \posreals$ and $\beta \in \posreals$, then for $y \in
\nats$,
\[
\distro{NegBinomial}(y|\alpha,\beta)
 =
\binom{y + \alpha - 1}{\alpha - 1}
\,
\left( \frac{\beta}{\beta+1} \right)^{\!\alpha}
\,
\left( \frac{1}{\beta + 1} \right)^{\!y} \!.
\]

% DON'T REMOVE --- WE MAY INCLUDE ALL THESE IN THE FUTURE ELSEWHERE
% \begin{eqnarray*}
% \log \distro{NegBinomial}(y|\alpha,\beta)
% & = & \log \Gamma(y + \alpha)
%   - \log \Gamma(y + 1)
%   - \log \Gamma(\alpha)
% \\[4pt]
% & &
%   {} + \alpha \left(\log \beta - \log (\beta + 1) \right)
%   - y \log (\beta + 1)
% \end{eqnarray*}
% \[
% \frac{\partial}{\partial \alpha}
% \log \distro{NegativeBinomial}(y|\alpha,\beta)
% = \Psi(y + \alpha)
% - \Psi(\alpha)
% + \log \beta
% - \log (\beta + 1)
% \]
% \[
% \frac{\partial}{\partial \beta}
% \log \distro{NegBinomial}(y|\alpha,\beta)
% = \frac{\alpha}{\beta} - \frac{\alpha + y}{\beta + 1}
% \]
% where $\Psi$ is the digamma function (see
% \refsection{digamma-appendix} for a definition).

The mean and variance of a random variable $y \sim
\distro{NegBinomial}(\alpha,\beta)$ are given by
\[
\mathbb{E}[y] = \frac{\alpha}{\beta}
\ \ \mbox{ and } \ \
\mbox{Var}[Y] = \frac{\alpha}{\beta^2} (\beta + 1).
\]

\pitemdisc{n}{neg\_binomial}{alpha, beta}

\subsubsection{Stan Functions}

\begin{description}
%
 \fitem{real}{neg\_binomial\_lpmf}{ints \farg{n} \textbar\ reals
   \farg{alpha}, reals \farg{beta}}{The log negative binomial probability
   mass of \farg{n} given shape \farg{alpha} and inverse scale \farg{beta}}
%
 \fitem{real}{neg\_binomial\_cdf}{ints \farg{n}, reals
   \farg{alpha}, reals \farg{beta}}{The negative binomial cumulative
   distribution function
   of \farg{n} given shape \farg{alpha} and inverse scale \farg{beta}}
%
 \fitem{real}{neg\_binomial\_lcdf}{ints \farg{n} \textbar\ reals
   \farg{alpha}, reals \farg{beta}}{The log of the negative binomial cumulative
   distribution function
   of \farg{n} given shape \farg{alpha} and inverse scale \farg{beta}}
%
 \fitem{real}{neg\_binomial\_lccdf}{ints \farg{n} \textbar\ reals
   \farg{alpha}, reals \farg{beta}}{The log of the negative binomial
   complementary cumulative distribution function of \farg{n}
   given shape \farg{alpha} and inverse scale \farg{beta}}
%
\fitem{int}{neg\_binomial\_rng}{real \farg{alpha}, real \farg{beta}}{Generate a
  negative binomial variate with shape \farg{alpha} and inverse scale
\farg{beta}; may only be used in generated quantities block. \farg{alpha} $/$ \farg{beta}
must be less than $2 ^ {29}$}
\end{description}


\section{Negative Binomial Distribution (alternative parameterization)}\label{nbalt.section}

Stan also provides an alternative parameterization of the negative
binomial distribution directly using a mean (i.e., location) parameter
and a parameter that controls overdispersion relative to the square of
the mean.  \refsection{neg-binom-2-log}, below, provides a second
alternative parameterization directly in terms of the log mean.

\subsubsection{Probability Mass Function}

The first parameterization is for $\mu \in \posreals$ and $\phi \in
\posreals$, which for $y \in \nats$ is defined as
\[
\distro{NegBinomial2}(y \, | \, \mu, \phi)
 =
\binom{y + \phi - 1}{y}
\,
\left( \frac{\mu}{\mu+\phi} \right)^{\!y}
\,
\left( \frac{\phi}{\mu+\phi} \right)^{\!\phi} \!.
\]

The mean and variance of a random variable $y \sim
\distro{NegBinomial2}(y|\mu,\phi)$ are
\[
\mathbb{E}[Y] = \mu
\ \ \ \mbox{ and } \ \ \
\mbox{Var}[Y] = \mu + \frac{\mu^2}{\phi}.
\]
Recall that $\distro{Poisson}(\mu)$ has variance $\mu$, so $\mu^2 /
\phi > 0$ is the additional variance of the negative binomial above
that of the Poisson with mean $\mu$.  So the inverse of parameter
$\phi$ controls the overdispersion, scaled by the square of the mean,
$\mu^2$.

\pitemdisc{y}{neg\_binomial\_2}{mu, phi}

\subsubsection{Stan Functions}

\begin{description}
%
 \fitem{real}{neg\_binomial\_2\_lpmf}{ints \farg{y} \textbar\ reals
   \farg{mu}, reals \farg{phi}}{The negative binomial probability
   mass of \farg{n} given location \farg{mu} and precision
   \farg{phi}.}
%
 \fitem{real}{neg\_binomial\_2\_cdf}{ints \farg{n}, reals
   \farg{mu}, reals \farg{phi}}{The negative binomial cumulative
   distribution function of \farg{n}
   given location \farg{mu} and precision \farg{phi}.}
%
 \fitem{real}{neg\_binomial\_2\_lcdf}{ints \farg{n} \textbar\ reals
   \farg{mu}, reals \farg{phi}}{The log of the negative binomial
   cumulative distribution function of \farg{n}
   given location \farg{mu} and precision  \farg{phi}.}
%
 \fitem{real}{neg\_binomial\_2\_lccdf}{ints \farg{n} \textbar\ reals
   \farg{mu}, reals \farg{phi}}{The log of the negative binomial
   complementary cumulative distribution function of \farg{n}
   given location \farg{mu} and precision \farg{phi}.}
%
\fitem{int}{neg\_binomial\_2\_rng}{real \farg{mu}, real \farg{phi}}{
  Generate a negative binomial variate with location
  \farg{mu} and precision \farg{phi}; may only be used in
  generated quantities block.
  \farg{mu} must be less than $2 ^ {29}$.}
%
\end{description}

\section{Negative Binomial Distribution (log alternative parameterization)}\label{neg-binom-2-log.section}

Related to the parameterization in \refsection{nbalt}, the following
parameterization uses a log mean parameter $\eta = \log(\mu)$, defined
for $\eta \in \reals$, $\phi \in \posreals$, so that for $y \in \nats$,
%
\[
\distro{NegBinomial2Log}(y \, | \, \eta, \phi)
=
\distro{NegBinomial2}(y | \exp(\eta), \phi).
\]
%
This alternative may be used for sampling, as a function, and for
random number generation, but as of yet, there are no CDFs implemented
for it.

\pitemdisc{y}{neg\_binomial\_2\_log}{eta, phi}

\section{Stan Functions}

\begin{description}
%
  \fitem{real}{neg\_binomial\_2\_log\_lpmf}{ints \farg{y} \textbar\ reals
    \farg{eta}, reals \farg{phi}}{The log negative binomial
    probability mass of \farg{n} given log-location \farg{eta} and
    inverse overdispersion control \farg{phi}. This is especially
    useful for log-linear negative binomial regressions.}
%
\fitem{int}{neg\_binomial\_2\_log\_rng}{real \farg{eta}, real \farg{phi}}{
  Generate a negative binomial variate with log-location \farg{eta}
  and inverse overdispersion control \farg{phi}; may only be used in generated
  quantities block. \farg{eta} must be less than $29 \log 2$.}
%
\end{description}

\section{Poisson Distribution}\label{poisson.section}

\subsubsection{Probability Mass Function}

If $\lambda \in \posreals$, then for $n \in \nats$,
\[
\distro{Poisson}(n|\lambda)
=
\frac{1}{n!}
\,
\lambda^n
\,
\exp(-\lambda).
\]

\pitemdisc{n}{poisson}{lambda}

\subsubsection{Stan Functions}

\begin{description}
\fitem{real}{poisson\_lpmf}{ints \farg{n} \textbar\ reals \farg{lambda}}{The
  log Poisson probability mass of \farg{n} given rate \farg{lambda}}
%
\fitem{real}{poisson\_cdf}{ints \farg{n}, reals \farg{lambda}}{The
  Poisson cumulative distribution function of \farg{n} given rate \farg{lambda}}
%
\fitem{real}{poisson\_lcdf}{ints \farg{n} \textbar\ reals \farg{lambda}}{The log of the
  Poisson cumulative distribution function of \farg{n} given rate \farg{lambda}}
%
\fitem{real}{poisson\_lccdf}{ints \farg{n} \textbar\ reals \farg{lambda}}{The log of the
  Poisson complementary cumulative distribution function of \farg{n} given rate \farg{lambda}}
%
\fitem{int}{poisson\_rng}{real \farg{lambda}}{Generate a Poisson variate with
  rate \farg{lambda}; may only be used in generated quantities block. \farg{lambda} must be
less than $2^{30}$.}
\end{description}


\section{Poisson Distribution, Log Parameterization}


Stan also provides a parameterization of the Poisson using the log
rate $\alpha = \log \lambda$ as a parameter.  This is useful for
log-linear Poisson regressions so that the predictor does not need to
be exponentiated and passed into the standard Poisson probability
function.

\subsubsection{Probability Mass Function}

If $\alpha \in \reals$, then for $n \in \nats$,
\[
\distro{PoissonLog}(n|\alpha)
=
\frac{1}{n!}
\,
\exp \left(n\alpha - \exp(\alpha) \right).
\]

\pitemdisc{n}{poisson\_log}{alpha}

\subsubsection{Stan Functions}

\begin{description}
\fitem{real}{poisson\_log\_lpmf}{ints \farg{n} \textbar\ reals \farg{alpha}}{The
  log Poisson probability mass of \farg{n} given log rate \farg{alpha}}
%
\fitem{int}{poisson\_log\_rng}{real \farg{alpha}}{Generate a Poisson variate with
log rate \farg{alpha}; may only be used in generated quantities block. \farg{alpha} must
be less than $30 \log 2$}
\end{description}




\chapter{Multivariate Discrete Distributions}

\noindent
The multivariate discrete distributions are over multiple integer
values, which are expressed in Stan as arrays.

\section{Multinomial Distribution}

\subsubsection{Probability Mass Function}

If $K \in \nats$, $N \in \nats$, and $\theta \in \mbox{$K$-simplex}$,
then for $y \in \nats^K$ such that $\sum_{k=1}^K y_k = N$,
%
\[
\distro{Multinomial}(y|\theta)
= \binom{N}{y_1,\ldots,y_K}
\prod_{k=1}^K \theta_k^{y_k},
\]
where the multinomial coefficient is defined by
\[
\binom{N}{y_1,\ldots,y_k}
= \frac{N!}{\prod_{k=1}^K y_k!}.
\]

\pitemdisc{y}{multinomial}{theta}

\subsubsection{Stan Functions}

\begin{description}
 \fitem{real}{multinomial\_lpmf}{int[] \farg{y} \textbar\ vector
    \farg{theta}}{The log multinomial probability mass function with
    outcome array \code{y} of size $K$ given the $K$-simplex
    distribution parameter \farg{theta} and (implicit) total count
    \code{N = sum(\farg{y})}}
%
\fitem{int[]}{multinomial\_rng}{vector \farg{theta}, int \farg{N}}{Generate a
  multinomial variate with simplex distribution parameter \farg{theta} and 
  total count \farg{N}; may only be used in generated quantities block}
\end{description}



\part{Continuous Distributions}\label{continuous-prob-functions.part}



\chapter{Unbounded Continuous Distributions}

\noindent
The unbounded univariate continuous probability distributions have
support on all real numbers.


\section{Normal Distribution}\label{normal-distribution.section}

\subsubsection{Probability Density Function}

If $\mu \in \reals$ and $\sigma \in \posreals$, then for $y \in
\reals$,
\[
\distro{Normal}(y|\mu,\sigma)
=
\frac{1}{\sqrt{2 \pi} \ \sigma}
\exp\left( - \, \frac{1}{2}
           \left(  \frac{y - \mu}{\sigma} \right)^2
    \right)
\!.
\]

\pitem{y}{normal}{mu, sigma}

\subsubsection{Stan Functions}

\begin{description}
  \fitem{real}{normal\_lpdf}{reals \farg{y} \textbar\ reals \farg{mu}, reals
    \farg{sigma}}{The log of the normal density of \farg{y} given
    location \farg{mu} and scale \farg{sigma}}
%
\fitem{real}{normal\_cdf}{reals \farg{y}, reals \farg{mu}, reals
  \farg{sigma}}{The cumulative normal distribution of \farg{y}
  given location \farg{mu} and scale \farg{sigma}; normal\_cdf will
  underflow to 0 for $\frac{{y}-{\mu}}{{\sigma}}$ below -37.5 and
  overflow to 1 for $\frac{{y}-{\mu}}{{\sigma}}$ above 8.25;  the
  function \code{Phi\_approx} is more robust in the tails, but must be
  scaled and translated for anything other than a unit normal.}
%
\fitem{real}{normal\_lcdf}{reals \farg{y} \textbar\ reals \farg{mu}, reals
  \farg{sigma}}{The log of the cumulative normal distribution of \farg{y}
  given location \farg{mu} and scale \farg{sigma}; normal\_lcdf
  will underflow to $-\infty$ for $\frac{{y}-{\mu}}{{\sigma}}$ below
  -37.5 and overflow to 0 for $\frac{{y}-{\mu}}{{\sigma}}$ above 8.25;
 see above for discussion of \code{Phi\_approx} as an alternative.}
%
\fitem{real}{normal\_lccdf}{reals \farg{y} \textbar\ reals \farg{mu}, reals
  \farg{sigma}}{The log of the complementary cumulative normal distribution
  of \farg{y} given location \farg{mu} and scale \farg{sigma};
  normal\_lccdf will overflow to 0 for
  $\frac{{y}-{\mu}}{{\sigma}}$ below -37.5 and underflow to $-\infty$
  for $\frac{{y}-{\mu}}{{\sigma}}$ above 8.25;
  see above for discussion of \code{Phi\_approx} as an alternative.}
\end{description}
%
\begin{description}
\fitem{real}{normal\_rng}{real \farg{mu} \textbar\ real \farg{sigma}}{Generate a normal
  variate with location \farg{mu} and scale \farg{sigma}; may only be used in
  generated quantities block}
\end{description}


\section{Exponentially Modified Normal Distribution}

\subsubsection{Probability Density Function}

If $\mu \in \reals$, $\sigma \in \posreals$, and $\lambda \in
\posreals$, then for $y \in \reals$,
\[
\distro{ExpModNormal}(y|\mu,\sigma,\lambda)
=
\frac{\lambda}{2}
\
\exp \left(\frac{\lambda}{2} \left(2\mu + \lambda \sigma^2 - 2y\right)\right) \erfc\left(\frac{\mu + \lambda\sigma^2 - y}{\sqrt{2}\sigma}\right)
.
\]

\pitem{y}{exp\_mod\_normal}{mu, sigma, lambda}

\subsubsection{Stan Functions}

\begin{description}
  \fitemtwolines{real}{exp\_mod\_normal\_lpdf}{reals \farg{y} \textbar\ reals
    \farg{mu}, reals \farg{sigma}}{reals \farg{lambda}}{The
    log of the exponentially modified normal density of \farg{y} given
    location \farg{mu}, scale \farg{sigma}, and shape \farg{lambda}}
%
  \fitemtwolines{real}{exp\_mod\_normal\_cdf}{reals \farg{y}, reals \farg{mu},
    reals \farg{sigma}}{reals \farg{lambda}}{The
    exponentially modified normal cumulative distribution function of \farg{y}
    given location \farg{mu}, scale \farg{sigma}, and shape \farg{lambda}}
%
  \fitemtwolines{real}{exp\_mod\_normal\_lcdf}{reals \farg{y} \textbar\ reals \farg{mu},
    reals \farg{sigma}}{reals \farg{lambda}}{The log of the
    exponentially modified normal cumulative distribution function of \farg{y}
    given location \farg{mu}, scale \farg{sigma}, and shape \farg{lambda}}
%
  \fitemtwolines{real}{exp\_mod\_normal\_lccdf}{reals \farg{y} \textbar\ reals \farg{mu},
    reals \farg{sigma}}{reals \farg{lambda}}{The log of the
    exponentially modified normal complementary cumulative distribution
    function of \farg{y} given location \farg{mu}, scale \farg{sigma}, and shape \farg{lambda}}
\end{description}
%
\begin{description}
\fitem{real}{exp\_mod\_normal\_rng}{real \farg{mu}, real \farg{sigma},
real \farg{lambda}}{Generate a exponentially modified normal variate
with location \farg{mu}, scale \farg{sigma}, and shape \farg{lambda};
may only be used in generated quantities block}
\end{description}

\section{Skew Normal Distribution}

\subsubsection{Probability Density Function}

If $\mu \in \reals$, $\sigma \in \posreals$, and $\alpha \in \reals$,
then for $y \in \reals$,
\[
\distro{SkewNormal}(y|\mu,\sigma,\alpha)
=
\frac{1}{\sigma\sqrt{2\pi}}
\
\exp\left( - \, \frac{1}{2}
           \left(  \frac{y - \mu}{\sigma} \right)^2
    \right)
\
\left(1 + \erf\left( \alpha\left(\frac{y - \mu}{\sigma\sqrt{2}}\right)\right)\right)
.
\]

\pitem{y}{skew\_normal}{mu, sigma, alpha}

\subsubsection{Stan Functions}

\begin{description}
  \fitem{real}{skew\_normal\_lpdf}{reals \farg{y} \textbar\ reals \farg{mu}, reals
    \farg{sigma}, reals \farg{alpha}}{The log of the skew normal density
	of \farg{y} given location \farg{mu}, scale \farg{sigma}, and
	shape \farg{alpha}}
%
\fitem{real}{skew\_normal\_cdf}{reals \farg{y}, reals \farg{mu}, reals
  \farg{sigma}, reals \farg{alpha}}{The skew normal
  distribution function of \farg{y} given location \farg{mu}, scale
  \farg{sigma}, and shape \farg{alpha}}
%
\fitemtwolines{real}{skew\_normal\_lcdf}{reals \farg{y} \textbar\ reals \farg{mu}, reals
  \farg{sigma}}{reals \farg{alpha}}{The log of the skew normal cumulative
  distribution function of \farg{y} given location \farg{mu}, scale
  \farg{sigma}, and shape \farg{alpha}}
%
\fitemtwolines{real}{skew\_normal\_lccdf}{reals \farg{y} \textbar\ reals \farg{mu}, reals
  \farg{sigma}}{reals \farg{alpha}}{The log of the skew normal complementary
   cumulative distribution function of \farg{y} given location \farg{mu}, scale
  \farg{sigma}, and shape \farg{alpha}}
\end{description}
%
\begin{description}
\fitem{real}{skew\_normal\_rng}{real \farg{mu}, real \farg{sigma},
  real \farg{alpha}}{Generate a skew normal variate with location
  \farg{mu}, scale \farg{sigma}, and shape \farg{alpha}; may only be used in
  generated quantities block}
\end{description}


\section{Student-$t$ Distribution}

\subsubsection{Probability Density Function}

If $\nu \in \posreals$, $\mu \in \reals$, and $\sigma \in \posreals$,
then for $y \in \reals$,
\[
\distro{StudentT}(y|\nu,\mu,\sigma)
=
\frac{\Gamma\left((\nu + 1)/2\right)}
     {\Gamma(\nu/2)}
\
\frac{1}{\sqrt{\nu \pi} \ \sigma}
\
\left(
1 + \frac{1}{\nu} \left(\frac{y - \mu}{\sigma}\right)^2
\right)^{-(\nu + 1)/2}
\! .
\]

\pitem{y}{student\_t}{nu, mu, sigma}

\subsubsection{Stan Functions}

\begin{description}
  \fitem{real}{student\_t\_lpdf}{reals \farg{y} \textbar\ reals \farg{nu}, reals
    \farg{mu}, reals \farg{sigma}}{The log of the Student-$t$ density of \farg{y}
    given degrees of freedom \farg{nu}, location \farg{mu}, and scale
    \farg{sigma}}
%
  \fitem{real}{student\_t\_cdf}{reals \farg{y}, reals \farg{nu}, reals
    \farg{mu}, reals \farg{sigma}}{The Student-$t$ cumulative
    distribution function of \farg{y}
    given degrees of freedom \farg{nu}, location \farg{mu}, and scale
    \farg{sigma}}
%
  \fitem{real}{student\_t\_lcdf}{reals \farg{y} \textbar\ reals \farg{nu}, reals
    \farg{mu}, reals \farg{sigma}}{The log of the Student-$t$ cumulative
    distribution function of \farg{y}
    given degrees of freedom \farg{nu}, location \farg{mu}, and scale
    \farg{sigma}}
%
  \fitem{real}{student\_t\_lccdf}{reals \farg{y} \textbar\ reals \farg{nu}, reals
    \farg{mu}, reals \farg{sigma}}{The log of the Student-$t$ complementary
    cumulative distribution function of \farg{y} given degrees of freedom
    \farg{nu}, location \farg{mu}, and scale \farg{sigma}}
\end{description}
%
\begin{description}
\fitem{real}{student\_t\_rng}{real \farg{nu}, real \farg{mu}, real
  \farg{sigma}}{Generate a Student-$t$ variate with degrees of freedom
\farg{nu}, location \farg{mu}, and scale \farg{sigma}; may only be used in
  generated quantities block}
\end{description}



\section{Cauchy Distribution}

\subsubsection{Probability Density Function}

If $\mu \in \reals$ and $\sigma \in \posreals$, then for $y \in \reals$,
\[
\distro{Cauchy}(y|\mu,\sigma)
=
\frac{1}{\pi \sigma}
\
\frac{1}{1 + \left((y - \mu)/\sigma\right)^2}
.
\]

\pitem{y}{cauchy}{mu, sigma}

\subsubsection{Stan Functions}

\begin{description}
%
\fitem{real}{cauchy\_lpdf}{reals \farg{y} \textbar\ reals \farg{mu}, reals
 \farg{sigma}}{ The log of the Cauchy density of \farg{y} given location
 \farg{mu} and scale \farg{sigma}}
%
\fitem{real}{cauchy\_cdf}{reals \farg{y}, reals \farg{mu}, reals
 \farg{sigma}}{ The Cauchy cumulative distribution function of \farg{y} given
  location \farg{mu} and scale \farg{sigma}}
%
\fitem{real}{cauchy\_lcdf}{reals \farg{y} \textbar\ reals \farg{mu}, reals
 \farg{sigma}}{ The log of the Cauchy cumulative distribution function
	of \farg{y} given location \farg{mu} and scale \farg{sigma}}
%
\fitem{real}{cauchy\_lccdf}{reals \farg{y} \textbar\ reals \farg{mu}, reals
 \farg{sigma}}{ The log of the Cauchy complementary cumulative distribution
  function of \farg{y} given location \farg{mu} and scale \farg{sigma}}
\end{description}
%
\begin{description}
\fitem{real}{cauchy\_rng}{real \farg{mu}, real \farg{sigma}}{Generate a Cauchy
  variate with location \farg{mu} and scale \farg{sigma}; may only be used in
  generated quantities block}
\end{description}


\section{Double Exponential (Laplace) Distribution}

\subsubsection{Probability Density Function}

If $\mu \in \reals$ and $\sigma \in \posreals$, then for $y \in \reals$,
\[
\distro{DoubleExponential}(y|\mu,\sigma)
= \frac{1}{2\sigma}
  \exp \left( - \, \frac{|y - \mu|}{\sigma} \right)
.
\]
Note that the double exponential distribution is parameterized in
terms of the scale, in contrast to the exponential distribution (see
\refsection{exponential-distribution}), which is parameterized in
terms of inverse scale.

The double-exponential distribution can be defined as a compound
exponential-normal distribution.  Specifically, if 
\[
\alpha \sim \mathsf{Exponential}\left( \frac{1}{\lambda} \right)
\]
and
\[
\beta \sim \mathsf{Normal}(\mu, \alpha),
\]
then
\[
\beta \sim \mathsf{DoubleExponential}(\mu, \lambda).
\]
This may be used to code a non-centered parameterization by taking
\[
\beta^{\mathrm{raw}} \sim \mathsf{Normal}(0, 1)
\]
and defining
\[
\beta = \mu + \alpha \, \beta^{\mathrm{raw}}.
\]

\pitem{y}{double\_exponential}{mu, sigma}

\subsubsection{Stan Functions}

\begin{description}
\fitem{real}{double\_exponential\_lpdf}{reals \farg{y} \textbar\ reals \farg{mu},
reals \farg{sigma}}{ The log of the double exponential density of \farg{y} given
location \farg{mu} and scale \farg{sigma}}
%
\fitem{real}{double\_exponential\_cdf}{reals \farg{y}, reals \farg{mu},
reals \farg{sigma}}{ The double exponential cumulative distribution
function of \farg{y} given location \farg{mu} and scale \farg{sigma}}
%
\fitem{real}{double\_exponential\_lcdf}{reals \farg{y} \textbar\ reals \farg{mu},
reals \farg{sigma}}{ The log of the double exponential cumulative distribution
function of \farg{y} given location \farg{mu} and scale \farg{sigma}}
%
\fitem{real}{double\_exponential\_lccdf}{reals \farg{y} \textbar\ reals \farg{mu},
reals \farg{sigma}}{ The log of the double exponential complementary cumulative distribution
function of \farg{y} given location \farg{mu} and scale \farg{sigma}}
\end{description}
%
\begin{description}
\fitem{real}{double\_exponential\_rng}{real \farg{mu}, real
  \farg{sigma}}{Generate a double exponential variate with location
  \farg{mu} and scale \farg{sigma}; may only be used in generated
  quantities block}
\end{description}


\section{Logistic Distribution}

\subsubsection{Probability Density Function}

If $\mu \in \reals$ and $\sigma \in \posreals$, then for $y \in \reals$,
\[
\distro{Logistic}(y|\mu,\sigma)
=
\frac{1}{\sigma}
\
\exp\!\left( - \, \frac{y - \mu}{\sigma} \right)
\
\left(1 + \exp \!\left( - \, \frac{y - \mu}{\sigma} \right) \right)^{\!-2}
\! .
\]


\pitem{y}{logistic}{mu, sigma}

\subsubsection{Stan Functions}

\begin{description}
\fitem{real}{logistic\_lpdf}{reals \farg{y} \textbar\ reals \farg{mu},
reals \farg{sigma}}{ The log of the logistic density of \farg{y} given
location \farg{mu} and scale \farg{sigma}}
%
\fitem{real}{logistic\_cdf}{reals \farg{y}, reals \farg{mu},
  reals \farg{sigma}}{ The logistic cumulative distribution function of
  \farg{y} given location \farg{mu} and scale \farg{sigma}}
%
\fitem{real}{logistic\_lcdf}{reals \farg{y} \textbar\ reals \farg{mu},
  reals \farg{sigma}}{ The log of the logistic cumulative distribution
  function of \farg{y} given location \farg{mu} and scale \farg{sigma}}
%
\fitem{real}{logistic\_lccdf}{reals \farg{y} \textbar\ reals \farg{mu},
  reals \farg{sigma}}{ The log of the logistic complementary cumulative
  distribution function of \farg{y} given location \farg{mu} and scale
  \farg{sigma}}
\end{description}
%
\begin{description}
\fitem{real}{logistic\_rng}{real \farg{mu}, real
  \farg{sigma}}{Generate a logistic variate with location \farg{mu}
  and scale \farg{sigma}; may only be used in generated quantities block}
\end{description}


\section{Gumbel Distribution}

\subsubsection{Probability Density Function}

If $\mu \in \reals$ and $\beta \in \posreals$, then for $y \in \reals$,
\[
\distro{Gumbel}(y|\mu,\beta)
=
\frac{1}{\beta}
\
\exp\left(-\frac{y-\mu}{\beta}-\exp\left(-\frac{y-\mu}{\beta}\right)\right)
.
\]

\pitem{y}{gumbel}{mu, beta}

\subsubsection{Stan Functions}

\begin{description}
  \fitem{real}{gumbel\_lpdf}{reals \farg{y} \textbar\ reals \farg{mu}, reals
    \farg{beta}}{The log of the gumbel density of \farg{y} given location
    \farg{mu} and scale \farg{beta}}
%
\fitem{real}{gumbel\_cdf}{reals \farg{y}, reals \farg{mu}, reals
  \farg{beta}}{The gumbel cumulative distribution function of \farg{y}
  given location \farg{mu} and scale \farg{beta}}
%
\fitem{real}{gumbel\_lcdf}{reals \farg{y} \textbar\ reals \farg{mu}, reals
  \farg{beta}}{The log of the gumbel cumulative distribution function of \farg{y}
  given location \farg{mu} and scale \farg{beta}}
%
\fitem{real}{gumbel\_lccdf}{reals \farg{y} \textbar\ reals \farg{mu}, reals
  \farg{beta}}{The log of the gumbel complementary cumulative distribution
   function of \farg{y} given location \farg{mu} and scale \farg{beta}}
\end{description}
%
\begin{description}
\fitem{real}{gumbel\_rng}{real \farg{mu}, real
  \farg{beta}}{Generate a gumbel variate with location \farg{mu}
  and scale \farg{beta}; may only be used in generated quantities block}
\end{description}


\chapter{Positive Continuous Distributions}

\noindent
The positive continuous probability functions have support on the
positive real numbers.


\section{Lognormal Distribution}\label{lognormal.section}

\subsubsection{Probability Density Function}

If $\mu \in \reals$ and $\sigma \in \posreals$, then for $y \in
\posreals$,
\[
\distro{LogNormal}(y|\mu,\sigma)
=
\frac{1}{\sqrt{2 \pi} \ \sigma}
\,
\frac{1}{y}
\
\exp \! \left(
       - \, \frac{1}{2}
       \, \left( \frac{\log y - \mu}{\sigma} \right)^2
     \right)
.
\]

\pitem{y}{lognormal}{mu, sigma}


\subsubsection{Stan Functions}

\begin{description}
 \fitem{real}{lognormal\_lpdf}{reals \farg{y} \textbar\ reals \farg{mu}, reals
  \farg{sigma}}{The log of the lognormal density of \farg{y} given location
  \farg{mu} and scale \farg{sigma}}
%
\fitem{real}{lognormal\_cdf}{reals \farg{y}, reals \farg{mu}, reals
  \farg{sigma}}{The cumulative lognormal distribution function of \farg{y}
  given location \farg{mu} and scale \farg{sigma}}
%
\fitem{real}{lognormal\_lcdf}{reals \farg{y} \textbar\ reals \farg{mu}, reals
  \farg{sigma}}{The log of the lognormal cumulative distribution fucntion
   of \farg{y} given location \farg{mu} and scale \farg{sigma}}
%
\fitem{real}{lognormal\_lccdf}{reals \farg{y} \textbar\ reals \farg{mu}, reals
  \farg{sigma}}{The log of the lognormal complementary cumulative distribution
  function of \farg{y} given location \farg{mu} and scale \farg{sigma}}
\end{description}
%
\begin{description}
\fitem{real}{lognormal\_rng}{real \farg{mu}, real
  \farg{beta}}{Generate a lognormal variate with location \farg{mu}
  and scale \farg{sigma}; may only be used in generated quantities block}
\end{description}


\section{Chi-Square Distribution}

\subsubsection{Probability Density Function}

If $\nu \in \posreals$, then for $y \in \posreals$,
\[
\distro{ChiSquare}(y|\nu)
=
\frac{2^{-\nu/2}}
    {\Gamma(\nu / 2)}
\,
y^{\nu/2 - 1}
\,
\exp \! \left( -\, \frac{1}{2} \, y \right)
.
\]

\pitem{y}{chi\_square}{nu}

\subsubsection{Stan Functions}

\begin{description}
\fitem{real}{chi\_square\_lpdf}{reals \farg{y} \textbar\ reals \farg{nu}}{The
  log of the Chi-square density of \farg{y} given degrees of freedom
  \farg{nu}}
%
\fitem{real}{chi\_square\_cdf}{reals \farg{y}, reals \farg{nu}}{The
   Chi-square cumulative distribution function of \farg{y} given degrees
   of freedom \farg{nu}}
%
\fitem{real}{chi\_square\_lcdf}{reals \farg{y} \textbar\ reals \farg{nu}}{The
   log of the Chi-square cumulative distribution function of
   \farg{y} given degrees of freedom \farg{nu}}
%
\fitem{real}{chi\_square\_lccdf}{reals \farg{y} \textbar\ reals \farg{nu}}{The
   log of the complementary Chi-square cumulative distribution
   function of \farg{y} given degrees of freedom \farg{nu}}
\end{description}
%
\begin{description}
\fitem{real}{chi\_square\_rng}{real \farg{nu}}{Generate a Chi-square
  variate with degrees of freedom \farg{nu}; may only be used in
  generated quantities block}
\end{description}



\section{Inverse Chi-Square Distribution}

\subsubsection{Probability Density Function}

If $\nu \in \posreals$, then for $y \in \posreals$,
\[
\distro{InvChiSquare}(y \, | \, \nu)
=
\frac{2^{-\nu/2}}
   {\Gamma(\nu / 2)}
\,
y^{-\nu/2 - 1}
\,
\exp\! \left( \! - \, \frac{1}{2} \, \frac{1}{y} \right)
.
\]

\pitem{y}{inv\_chi\_square}{nu}


\subsubsection{Stan Functions}

\begin{description}
\fitem{real}{inv\_chi\_square\_lpdf}{reals \farg{y} \textbar\ reals
  \farg{nu}}{The log of the inverse Chi-square density of \farg{y} given
  degrees of freedom \farg{nu}}
%
\fitem{real}{inv\_chi\_square\_cdf}{reals \farg{y}, reals
  \farg{nu}}{The inverse Chi-squared cumulative distribution function of
  \farg{y} given degrees of freedom \farg{nu}}
%
\fitem{real}{inv\_chi\_square\_lcdf}{reals \farg{y} \textbar\ reals
  \farg{nu}}{The log of the inverse Chi-squared cumulative distribution
   function of \farg{y} given degrees of freedom \farg{nu}}
%
\fitem{real}{inv\_chi\_square\_lccdf}{reals \farg{y} \textbar\ reals
  \farg{nu}}{The log of the inverse Chi-squared complementary cumulative
  distribution function of \farg{y} given degrees of freedom \farg{nu}}
\end{description}
%
\begin{description}
\fitem{real}{inv\_chi\_square\_rng}{real \farg{nu}}{Generate an
  inverse Chi-squared variate with degrees of freedom \farg{nu};
may only be used in generated quantities block}
\end{description}


\section{Scaled Inverse Chi-Square Distribution}

\subsubsection{Probability Density Function}

If $\nu \in \posreals$ and $\sigma \in \posreals$, then for $y \in
\posreals$,
\[
\distro{ScaledInvChiSquare}(y|\nu,\sigma)
=
\frac{(\nu / 2)^{\nu/2}}
     {\Gamma(\nu / 2)}
\,
\sigma^{\nu}
\,
y^{-(\nu/2 + 1)}
\,
\exp \! \left( \!
   - \, \frac{1}{2} \, \nu \, \sigma^2 \, \frac{1}{y}
\right)
.
\]


\pitem{y}{scaled\_inv\_chi\_square}{nu, sigma}

\subsubsection{Stan Functions}

\begin{description}
  \fitem{real}{scaled\_inv\_chi\_square\_lpdf}{reals \farg{y} \textbar\ reals
    \farg{nu}, reals \farg{sigma}}{The log of the scaled inverse Chi-square
    density of \farg{y} given degrees of freedom \farg{nu} and scale
    \farg{sigma}}
\end{description}
%
\begin{description}
  \fitem{real}{scaled\_inv\_chi\_square\_cdf}{reals \farg{y}, reals
    \farg{nu}, reals \farg{sigma}}{The scaled inverse Chi-square
    cumulative distribution function
    of \farg{y} given degrees of freedom \farg{nu} and scale
    \farg{sigma}}
%
  \fitem{real}{scaled\_inv\_chi\_square\_lcdf}{reals \farg{y} \textbar\ reals
    \farg{nu}, reals \farg{sigma}}{The log of the scaled inverse Chi-square
    cumulative distribution function
    of \farg{y} given degrees of freedom \farg{nu} and scale
    \farg{sigma}}
%
  \fitem{real}{scaled\_inv\_chi\_square\_lccdf}{reals \farg{y} \textbar\ reals
    \farg{nu}, reals \farg{sigma}}{The log of the scaled inverse Chi-square
    complementary cumulative distribution function
    of \farg{y} given degrees of freedom \farg{nu} and scale
    \farg{sigma}}
\end{description}
%
\begin{description}
\fitem{real}{scaled\_inv\_chi\_square\_rng}{real \farg{nu}, real
  \farg{sigma}}{Generate a scaled inverse Chi-squared variate with degrees
of freedom \farg{nu} and scale \farg{sigma}; may only be used in generated
quantities block}
\end{description}


\section{Exponential Distribution}\label{exponential-distribution.section}

\subsubsection{Probability Density Function}

If $\beta \in \posreals$, then for $y \in \posreals$,
\[
\distro{Exponential}(y|\beta)
=
\beta \,
\exp ( - \beta \, y )
.
\]

\pitem{y}{exponential}{beta}

\subsubsection{Stan Functions}

\begin{description}
  \fitem{real}{exponential\_lpdf}{reals \farg{y} \textbar\ reals \farg{beta}}{The
    log of the exponential density of \farg{y} given inverse scale \farg{beta}}
%
\fitem{real}{exponential\_cdf}{reals \farg{y}, reals \farg{beta}}{The
  exponential cumulative distribution function of \farg{y} given inverse scale
  \farg{beta}}
%
\fitem{real}{exponential\_lcdf}{reals \farg{y} \textbar\ reals \farg{beta}}{The
  log of the exponential cumulative distribution function of \farg{y} given
  inverse scale \farg{beta}}
%
\fitem{real}{exponential\_lccdf}{reals \farg{y} \textbar\ reals \farg{beta}}{The
  log of the exponential complementary cumulative distribution function
  of \farg{y} given inverse scale \farg{beta}}
\end{description}
%
\begin{description}
\fitem{real}{exponential\_rng}{real \farg{beta}}{Generate an
  exponential variate with inverse scale \farg{beta}; may only be used in
  generated quantities block}
\end{description}


\section{Gamma Distribution}

\subsubsection{Probability Density Function}

If $\alpha \in \posreals$ and $\beta \in \posreals$, then for $y \in
\posreals$,
\[
\distro{Gamma}(y|\alpha,\beta)
=
\frac{\beta^{\alpha}}
     {\Gamma(\alpha)}
\,
y^{\alpha - 1}
\exp(-\beta \, y)
.
\]


\pitem{y}{gamma}{alpha, beta}

\subsubsection{Stan Functions}

\begin{description}
 \fitem{real}{gamma\_lpdf}{reals \farg{y} \textbar\ reals \farg{alpha}, reals
  \farg{beta}}{The log of the gamma density of \farg{y} given shape
  \farg{alpha} and inverse scale \farg{beta}}
%
 \fitem{real}{gamma\_cdf}{reals \farg{y}, reals \farg{alpha}, reals
   \farg{beta}}{The cumulative gamma distribution function of \farg{y} given shape
   \farg{alpha} and inverse scale \farg{beta}}
%
 \fitem{real}{gamma\_lcdf}{reals \farg{y} \textbar\ reals \farg{alpha}, reals
   \farg{beta}}{The log of the cumulative gamma distribution function of \farg{y} given shape
   \farg{alpha} and inverse scale \farg{beta}}
%
 \fitem{real}{gamma\_lccdf}{reals \farg{y} \textbar\ reals \farg{alpha}, reals
   \farg{beta}}{The log of the complementary cumulative gamma distribution function of
   \farg{y} given shape \farg{alpha} and inverse scale \farg{beta}}
\end{description}
%
\begin{description}
\fitem{real}{gamma\_rng}{real \farg{alpha}, real
  \farg{beta}}{Generate a gamma variate with shape
  \farg{alpha} and inverse scale \farg{beta}; may only be used in generated
quantities block}
\end{description}


\section{Inverse Gamma Distribution}

\subsubsection{Probability Density Function}

If $\alpha \in \posreals$ and $\beta \in \posreals$, then for $y \in
\posreals$,
\[
\distro{InvGamma}(y|\alpha,\beta)
=
\frac{\beta^{\alpha}}
     {\Gamma(\alpha)}
\
y^{-(\alpha + 1)}
\,
\exp \! \left( \! - \beta \, \frac{1}{y} \right)
.
\]

\pitem{y}{inv\_gamma}{alpha, beta}


\subsubsection{Stan Functions}

\begin{description}
\fitem{real}{inv\_gamma\_lpdf}{reals \farg{y} \textbar\ reals \farg{alpha}, reals
  \farg{beta}}{The log of the inverse gamma density of \farg{y} given shape
  \farg{alpha} and scale \farg{beta}}
%
\fitem{real}{inv\_gamma\_cdf}{reals \farg{y}, reals \farg{alpha}, reals
  \farg{beta}}{The inverse gamma cumulative distribution function of \farg{y}
  given shape \farg{alpha} and scale \farg{beta}}
%
\fitem{real}{inv\_gamma\_lcdf}{reals \farg{y} \textbar\ reals \farg{alpha}, reals
  \farg{beta}}{The log of the inverse gamma cumulative distribution function
  of \farg{y} given shape \farg{alpha} and scale \farg{beta}}
%
\fitem{real}{inv\_gamma\_lccdf}{reals \farg{y} \textbar\ reals \farg{alpha}, reals
  \farg{beta}}{The log of the inverse gamma complementary cumulative distribution
  function of \farg{y} given shape \farg{alpha} and scale \farg{beta}}
\end{description}
%
\begin{description}
\fitem{real}{inv\_gamma\_rng}{real \farg{alpha}, real
  \farg{beta}}{Generate an inverse gamma variate with shape
  \farg{alpha} and scale \farg{beta}; may only be used in generated
quantities block}
\end{description}


\section{Weibull Distribution}

\subsubsection{Probability Density Function}

If $\alpha \in \posreals$ and $\sigma \in \posreals$, then for $y \in
[0,\infty)$,
\[
\distro{Weibull}(y|\alpha,\sigma)
=
\frac{\alpha}{\sigma}
\,
\left( \frac{y}{\sigma} \right)^{\alpha - 1}
\,
\exp \! \left( \! - \left( \frac{y}{\sigma} \right)^{\alpha}  \right)
.
\]

Note that if $Y \propto \distro{Weibull}(\alpha,\sigma)$,
then $Y^{-1} \propto \distro{Frechet}(\alpha,\sigma^{-1})$.

\pitem{y}{weibull}{alpha, sigma}

\subsubsection{Stan Functions}

\begin{description}
\fitem{real}{weibull\_lpdf}{reals \farg{y} \textbar\ reals \farg{alpha}, reals
  \farg{sigma}}{The log of the Weibull density of \farg{y} given shape
  \farg{alpha} and scale \farg{sigma}}
%
\fitem{real}{weibull\_cdf}{reals \farg{y}, reals \farg{alpha}, reals
  \farg{sigma}}{The Weibull cumulative distribution function of \farg{y} given
  shape \farg{alpha} and scale \farg{sigma}}
%
\fitem{real}{weibull\_lcdf}{reals \farg{y} \textbar\ reals \farg{alpha}, reals
  \farg{sigma}}{The log of the Weibull cumulative distribution function of
  \farg{y} given shape \farg{alpha} and scale \farg{sigma}}
%
\fitem{real}{weibull\_lccdf}{reals \farg{y} \textbar\ reals \farg{alpha}, reals
  \farg{sigma}}{The log of the Weibull complementary cumulative
  distribution function of \farg{y} given shape \farg{alpha} and scale
  \farg{sigma}}
\end{description}
%
\begin{description}
\fitem{real}{weibull\_rng}{real \farg{alpha}, real
  \farg{sigma}}{Generate a weibull variate with shape
  \farg{alpha} and scale \farg{sigma}; may only be used in generated
quantities block}
\end{description}

\section{Fr\'{e}chet Distribution}

\subsubsection{Probability Density Function}

If $\alpha \in \posreals$ and $\sigma \in \posreals$, then for $y \in
\posreals$,
\[
\distro{Frechet}(y|\alpha,\sigma)
=
\frac{\alpha}{\sigma}
\,
\left( \frac{y}{\sigma} \right)^{-\alpha - 1}
\,
\exp \! \left( \! - \left( \frac{y}{\sigma} \right)^{-\alpha}  \right)
.
\]

Note that if $Y \propto \distro{Frechet}(\alpha,\sigma)$,
then $Y^{-1} \propto \distro{Weibull}(\alpha,\sigma^{-1})$.

\pitem{y}{frechet}{alpha, sigma}

\subsubsection{Stan Functions}

\begin{description}
\fitem{real}{frechet\_lpdf}{reals \farg{y} \textbar\ reals \farg{alpha}, reals
  \farg{sigma}}{The log of the Fr\'{e}chet density of \farg{y} given shape
  \farg{alpha} and scale \farg{sigma}}
%
\fitem{real}{frechet\_cdf}{reals \farg{y}, reals \farg{alpha}, reals
  \farg{sigma}}{The Fr\'{e}chet cumulative distribution function of \farg{y} given
  shape \farg{alpha} and scale \farg{sigma}}
%
\fitem{real}{frechet\_lcdf}{reals \farg{y} \textbar\ reals \farg{alpha}, reals
  \farg{sigma}}{The log of the Fr\'{e}chet cumulative distribution function of
  \farg{y} given shape \farg{alpha} and scale \farg{sigma}}
%
\fitem{real}{frechet\_lccdf}{reals \farg{y} \textbar\ reals \farg{alpha}, reals
  \farg{sigma}}{The log of the Fr\'{e}chet complementary cumulative
  distribution function of \farg{y} given shape \farg{alpha} and scale
  \farg{sigma}}
\end{description}
%
\begin{description}
\fitem{real}{frechet\_rng}{real \farg{alpha}, real
  \farg{sigma}}{Generate an Fr\'{e}chet variate with shape
  \farg{alpha} and scale \farg{sigma}; may only be used in generated
quantities block}
\end{description}


\chapter{Non-negative Continuous Distributions}
\noindent
The non-negative continuous probability functions have support on the
non-negative real numbers.

\section{Rayleigh Distribution}

\subsubsection{Probability Density Function}
 If $\sigma \in \posreals$, then for $y \in [0,\infty)$,
\[
\distro{Rayleigh}(y|\sigma)
=
\frac{y}{\sigma^2} \exp(-y^2 / 2\sigma^2)
\!.
\]

\pitem{y}{rayleigh}{sigma}

\subsubsection{Stan Functions}
\begin{description}
\fitem{real}{rayleigh\_lpdf}{reals \farg{y} \textbar\ reals \farg{sigma}}{The log of the Rayleigh
 ensity of \farg{y} given scale \farg{sigma}}
%
\fitem{real}{rayleigh\_cdf}{real \farg{y}, real
\farg{sigma}}{The Rayleigh cumulative distribution of \farg{y} given scale \farg{sigma}}
%
\fitem{real}{rayleigh\_lcdf}{real \farg{y} \textbar\ real \farg{sigma}}{The log of the
 Rayleigh cumulative distribution of \farg{y} given scale \farg{sigma}}
%
\fitem{real}{rayleigh\_lccdf}{real \farg{y} \textbar\ real
\farg{sigma}}{The log of the Rayleigh complementary cumulative distribution
 of \farg{y} given scale \farg{sigma}}
\end{description}
%
\begin{description}
\fitem{real}{rayleigh\_rng}{real
  \farg{sigma}}{Generate a Rayleigh variate with scale
  \farg{sigma}; may only be used in generated
quantities block}
\end{description}

\section{Wiener Diffusion Model Distributions}

\subsubsection{Probability Density Function}

If $\alpha \in \posreals$, $\tau \in \posreals$, $\beta \in [0, 1]$
and $\delta \in \reals$, then for $y \in (0, \tau)$,
%
\[
\distro{Wiener}(y|\alpha, \tau, \beta, \delta)
=
\frac{\alpha}{(y-\tau)^3/2}
%
\exp \! \left(- \delta \alpha \beta - \frac{\delta^2(y-\tau)}{2}\right)
%
\sum_{k = - \infty}^{\infty} (2k + \beta)
%
\phi \! \left(\frac{2k + \alpha \beta}{\sqrt{y - \tau}}\right)
\]
%
where $\phi(x)$ denotes the standard normal density function
\citep{Blurton2012}.

\pitem{y}{wiener}{alpha, tau, beta, delta}

\subsubsection{Stan Functions}
\begin{description}
\fitemtwolines{real}{wiener\_lpdf}{reals \farg{y} \textbar\ reals \farg{alpha},
 reals \farg{tau}, reals \farg{beta}}{reals \farg{delta}}
 {The log of the Wiener first passage time
 density of \farg{y} given boundary separation \farg{alpha},
 non-decision time \farg{tau}, a-priori bias \farg{beta} and
 drift rate \farg{delta}}
\end{description}

\subsubsection{Boundaries}

Stan returns the first passage time of the accumulation process
over the upper boundary only. Therefore, one needs to calculate:
\[
\distro{wiener}(y|\alpha, \tau, 1 - \beta, - \delta).
\]

To get the result for the lower
boundary. For more details, see the appendix of
\citet{Vandekerckhove-Wabersich:2014}.

\chapter{Positive Lower-Bounded Probabilities}

\noindent
The positive lower-bounded probabilities have support on real values
above some positive minimum value.


\section{Pareto Distribution}

\subsubsection{Probability Density Function}

If $y_{\mbox{\footnotesize\rm min}} \in \posreals$ and $\alpha \in \posreals$, then for
$y \in \posreals$ with $y \geq y_{\mbox{\footnotesize\rm min}}$,
\[
\distro{Pareto}(y|y_{\mbox{\footnotesize\rm min}},\alpha)
=
\frac{\displaystyle \alpha\,y_{\mbox{\footnotesize\rm min}}^\alpha}{\displaystyle y^{\alpha+1}}.
\]

\pitem{y}{pareto}{y\_min, alpha}

\subsubsection{Stan Functions}

\begin{description}
  \fitem{real}{pareto\_lpdf}{reals \farg{y} \textbar\ reals \farg{y\_min}, reals
    \farg{alpha}}{The log of the Pareto density of \farg{y} given
    positive minimum value \farg{y\_min} and shape \farg{alpha}}
%
  \fitem{real}{pareto\_cdf}{reals \farg{y}, reals \farg{y\_min}, reals
    \farg{alpha}}{The Pareto cumulative distribution function of \farg{y} given
    positive minimum value \farg{y\_min} and shape \farg{alpha}}
%
  \fitem{real}{pareto\_lcdf}{reals \farg{y} \textbar\ reals \farg{y\_min}, reals
    \farg{alpha}}{The log of the Pareto cumulative distribution function of
    \farg{y} given positive minimum value \farg{y\_min} and shape \farg{alpha}}
%
  \fitem{real}{pareto\_lccdf}{reals \farg{y} \textbar\ reals \farg{y\_min}, reals
    \farg{alpha}}{The log of the Pareto complementary cumulative distribution
    function of \farg{y} given positive minimum value \farg{y\_min} and shape
    \farg{alpha}}
\end{description}
%
\begin{description}
\fitem{real}{pareto\_rng}{real \farg{y\_min}, real
  \farg{alpha}}{Generate a Pareto variate with positive minimum value
  \farg{y\_min} and shape \farg{alpha}; may only be used in generated
  quantities block}
\end{description}

\section{Pareto Type 2 Distribution}

\subsubsection{Probability Density Function}

If $\mu \in \reals$, $\lambda \in \posreals$, and $\alpha \in \posreals$, then for
$y \geq \mu$,
\[
\distro{Pareto\_Type\_2}(y|\mu,\lambda,\alpha)
=
\ \frac{\alpha}{\lambda}
\, \left( 1+\frac{y-\mu}{\lambda} \right)^{-(\alpha+1)}
\! .
\]

Note that the Lomax distribution is a Pareto Type 2 distribution with $\mu=0$.

\pitem{y}{pareto\_type\_2}{mu, lambda, alpha}

\subsubsection{Stan Functions}

\begin{description}
  \fitemtwolines{real}{pareto\_type\_2\_lpdf}{reals \farg{y} \textbar\ reals \farg{mu}, reals \farg{lambda}}{reals
    \farg{alpha}}{The log of the Pareto Type 2 density of \farg{y} given
    location \farg{mu}, scale \farg{lambda}, and shape \farg{alpha}}
%
  \fitemtwolines{real}{pareto\_type\_2\_cdf}{reals \farg{y}, reals \farg{mu}, reals \farg{lambda}}{reals
    \farg{alpha}}{The Pareto Type 2 cumulative distribution function of \farg{y} given
    location \farg{mu}, scale \farg{lambda}, and shape \farg{alpha}}
%
  \fitemtwolines{real}{pareto\_type\_2\_lcdf}{reals \farg{y} \textbar\ reals \farg{mu}, reals \farg{lambda}}{reals
    \farg{alpha}}{The log of the Pareto Type 2 cumulative distribution function of \farg{y} given
    location \farg{mu}, scale \farg{lambda}, and shape \farg{alpha}}
%
  \fitemtwolines{real}{pareto\_type\_2\_lccdf}{reals \farg{y} \textbar\ reals \farg{mu}, reals \farg{lambda}}{reals
    \farg{alpha}}{The log of the Pareto Type 2 complementary cumulative distribution function
     of \farg{y} given location \farg{mu}, scale \farg{lambda}, and shape \farg{alpha}}
\end{description}
%
\begin{description}
\fitem{real}{pareto\_type\_2\_rng}{real \farg{mu}, real \farg{lambda}, real
  \farg{alpha}}{Generate a Pareto Type 2 variate with location
  \farg{mu}, scale \farg{lambda}, and shape \farg{alpha}; may only be used in generated
  quantities block}
\end{description}


\chapter{Continuous Distributions on [0, 1]}

\noindent
The continuous distributions with outcomes in the interval $[0,1]$ are
used to characterized bounded quantities, including probabilities.


\section{Beta Distribution}

\subsubsection{Probability Density Function}

If $\alpha \in \posreals$ and $\beta \in \posreals$, then for $\theta
\in (0,1)$,
\[
\distro{Beta}(\theta|\alpha,\beta)
=
\frac{1}{\Betafun(\alpha,\beta)}
\,
\theta^{\alpha - 1}
\,
(1 - \theta)^{\beta - 1}
,
\]
where the beta function $\Betafun()$ is as defined in
\refsection{betafun}.

{\it Warning:}\ If $\theta = 0$ or $\theta = 1$, then the probability
is 0 and the log probability is $-\infty$.  Similarly, the
distribution requires strictly positive parameters, $\alpha, \beta >
0$.

\pitem{theta}{beta}{alpha, beta}

\subsubsection{Stan Functions}

\begin{description}
%
  \fitem{real}{beta\_lpdf}{reals \farg{theta} \textbar\ reals \farg{alpha}, reals
    \farg{beta}}{The log of the beta density of \code{theta} in $[0,1]$
    given positive prior successes (plus one)
    \farg{alpha} and prior failures (plus one) \farg{beta}}
%
  \fitem{real}{beta\_cdf}{reals \farg{theta}, reals \farg{alpha}, reals
    \farg{beta}}{The beta cumulative distribution function of \code{theta}
    in $[0,1]$ given positive prior successes (plus one)
    \farg{alpha} and prior failures (plus one) \farg{beta}}
%
  \fitem{real}{beta\_lcdf}{reals \farg{theta} \textbar\ reals \farg{alpha}, reals
    \farg{beta}}{The log of the beta cumulative distribution function of
    \code{theta} in $[0,1]$ given positive prior successes (plus one)
    \farg{alpha} and prior failures (plus one) \farg{beta}}
%
  \fitem{real}{beta\_lccdf}{reals \farg{theta} \textbar\ reals \farg{alpha}, reals
    \farg{beta}}{The log of the beta complementary cumulative distribution
    function of \code{theta} in $[0,1]$ given positive prior successes (plus one)
    \farg{alpha} and prior failures (plus one) \farg{beta}}
\end{description}
%
\begin{description}
\fitem{real}{beta\_rng}{real \farg{alpha}, real
  \farg{beta}}{Generate a beta variate with positive prior successes (plus one)
    \farg{alpha} and prior failures (plus one) \farg{beta}; may only
    be used in generated quantities block}
\end{description}


\chapter{Circular Distributions}

\noindent
Circular distributions are defined for finite values \farg{y} in any
interval of length $2\pi$.


\section{Von Mises Distribution}

\subsubsection{Probability Density Function}

If $\mu \in \reals$ and $\kappa \in \posreals$, then for $y \in
\reals$,
%
\[
\distro{VonMises}(y|\mu,\kappa)
=
\frac{\exp(\kappa\cos(y-\mu))}{2\pi I_0(\kappa)}
\!.
\]
%
In order for this density to properly normalize, $y$ must be
restricted to some interval  $(c, c + 2\pi)$ of length $2 \pi$,
because
%
\[
\int_{c}^{c + 2\pi} \distro{VonMises}(y|\mu,\kappa) dy
= 1.
\]
%
Similarly, if $\mu$ is a parameter, it will typically be restricted to
the same range as $y$.

A von Mises distribution with its $2 \pi$ interval of support centered
around its location $\mu$ will have a single mode at $\mu$; for
example, restricting $y$ to $(-\pi,\pi)$ and taking $\mu = 0$ leads to
a single local optimum at the model $\mu$.  If the location $\mu$ is
not in the center of the support, the density is circularly translated
and there will be a second local maximum at the boundary furthest from
the mode.  Ideally, the parameterization and support will be set up so
that the bulk of the probability mass is in a continuous interval
around the mean $\mu$.

\pitem{y}{von\_mises}{mu, kappa}

\subsubsection{Stan Functions}

\begin{description}
  \fitem{real}{von\_mises\_lpdf}{reals \farg{y} \textbar\ reals \farg{mu}, reals
    \farg{kappa}}{The log of the von mises density of \farg{y} given
    location \farg{mu} and scale \farg{kappa}}
\end{description}

\begin{description}
  \fitem{real}{von\_mises\_rng}{reals \farg{mu}, reals
    \farg{kappa}}{Generate a Von Mises variate with location
  \farg{mu} and scale \farg{kappa} (i.e. returns values in the interval $[(\mu \mod 2\pi)-\pi,(\mu \mod 2\pi)+\pi]$); may only
    be used in generated quantities block}
\end{description}
\subsubsection{Numerical Stability}

Evaluating the Von Mises distribution for $\kappa > 100$ is
numerically unstable in the current implementation.  Nathanael I.\
Lichti suggested the following workaround on the Stan users group,
based on the fact that as $\kappa \rightarrow \infty$,
\[
\distro{VonMises}(y|\mu,\kappa) \rightarrow \distro{Normal}(\mu,
\sqrt{1 / \kappa}).
\]
%
The workaround is to replace \Verb|y ~ von_mises(mu,kappa)| with
%
\begin{stancode}
if (kappa < 100)
  y ~ von_mises(mu, kappa);
else
  y ~ normal(mu, sqrt(1 / kappa));
\end{stancode}


\chapter{Bounded Continuous Probabilities}

\noindent
The bounded continuous probabilities have support on a finite interval
of real numbers.



\section{Uniform Distribution}

\subsubsection{Probability Density Function}

If $\alpha \in \reals$ and $\beta \in (\alpha,\infty)$, then for $y
\in [\alpha,\beta]$,
\[
\distro{Uniform}(y|\alpha,\beta)
=
\frac{1}{\beta - \alpha}
.
\]

\pitem{y}{uniform}{alpha, beta}

\subsubsection{Stan Functions}

\begin{description}
\fitem{real}{uniform\_lpdf}{reals \farg{y} \textbar\ reals \farg{alpha}, reals
  \farg{beta}}{The log of the uniform density of \farg{y} given lower bound
  \farg{alpha} and upper bound \farg{beta}}
%
\fitem{real}{uniform\_cdf}{reals \farg{y}, reals \farg{alpha}, reals
  \farg{beta}}{The uniform cumulative distribution function of \farg{y} given
  lower bound \farg{alpha} and upper bound \farg{beta}}
%
\fitem{real}{uniform\_lcdf}{reals \farg{y} \textbar\ reals \farg{alpha}, reals
  \farg{beta}}{The log of the uniform cumulative distribution function of
  \farg{y} given lower bound \farg{alpha} and upper bound \farg{beta}}
%
\fitem{real}{uniform\_lccdf}{reals \farg{y} \textbar\ reals \farg{alpha}, reals
  \farg{beta}}{The log of the uniform complementary cumulative distribution
  function of \farg{y} given lower bound \farg{alpha} and upper bound
  \farg{beta}}
\end{description}
%
\begin{description}
\fitem{real}{uniform\_rng}{real \farg{alpha}, real
  \farg{beta}}{Generate a uniform variate with lower bound
  \farg{alpha} and upper bound \farg{beta}; may only
    be used in generated quantities block}
\end{description}



\chapter{Distributions over Unbounded Vectors}

\noindent
The unbounded vector probability distributions have support on all of
$\reals^K$ for some fixed $K$.


\section{Multivariate Normal Distribution}

\subsubsection{Probability Density Function}

If $K \in \nats$, $\mu \in \reals^K$, and $\Sigma \in \reals^{K \times
  K}$ is symmetric and positive definite, then for $y \in \reals^K$,
\[
\distro{MultiNormal}(y|\mu,\Sigma)
=
\frac{1}{\left( 2 \pi \right)^{K/2}}
\
\frac{1}{\sqrt{|\Sigma|}}
\
\exp \! \left( \!
-
\frac{1}{2}
(y - \mu)^{\top} \, \Sigma^{-1} \, (y - \mu)
\right)
\! ,
\]
%
where $|\Sigma|$ is the absolute determinant of $\Sigma$.

\pitem{y}{multi\_normal}{mu, Sigma}

\subsubsection{Stan Functions}

The multivariate normal probability function is overloaded to allow
the variate vector $y$ and location vector $\mu$ to be vectors or row
vectors (or to mix the two types).  The density function is also
vectorized, so it allows arrays of row vectors or vectors as
arguments; see \refsection{prob-vectorization} for a description of
vectorization.

\begin{description}
%
  \fitem{real}{multi\_normal\_lpdf}{vectors \farg{y} \textbar\ vectors
    \farg{mu}, matrix \farg{Sigma}}{The log of the multivariate normal
    density of vector(s) \farg{y} given location vector(s) \farg{mu} and
    covariance matrix \farg{Sigma}}
%
  \fitem{real}{multi\_normal\_lpdf}{vectors \farg{y} \textbar\ row\_vectors
    \farg{mu}, matrix \farg{Sigma}}{The log of the multivariate normal
    density of vector(s) \farg{y} given location row vector(s)
    \farg{mu} and covariance matrix \farg{Sigma}}
%
  \fitem{real}{multi\_normal\_lpdf}{row\_vectors \farg{y} \textbar\ vectors
    \farg{mu}, matrix \farg{Sigma}}{The log of the multivariate normal
    density of row vector(s) \farg{y} given location vector(s)
    \farg{mu} and covariance matrix \farg{Sigma}}
%
  \fitem{real}{multi\_normal\_lpdf}{row\_vectors \farg{y} \textbar\ row\_vectors
    \farg{mu}, matrix \farg{Sigma}}{The log of the multivariate normal
    density of row vector(s) \farg{y} given location row vector(s)
    \farg{mu} and covariance matrix \farg{Sigma}}
%
\end{description}

Although there is a direct multi-normal RNG function, if more than one
result is required, it's much more efficient to Cholesky factor the
covariance matrix and call \code{multi\_normal\_cholesky\_rng};  see \refsection{multi-normal-cholesky-fun}.

\begin{description}
\fitem{vector}{multi\_normal\_rng}{vector \farg{mu}, matrix
  \farg{Sigma}}{Generate a multivariate normal variate with location
  \farg{mu} and covariance matrix \farg{Sigma}; may only be used in
generated quantities block}
\end{description}


\section{Multivariate Normal Distribution, Precision Parameterization}

\subsubsection{Probability Density Function}

If $K \in \nats$, $\mu \in \reals^K$, and $\Omega \in \reals^{K \times
  K}$ is symmetric and positive definite, then for $y \in \reals^K$,
%
\[
\distro{MultiNormalPrecision}(y|\mu,\Omega)
= \distro{MultiNormal}(y|\mu,\Sigma^{-1})
\]

\pitem{y}{multi\_normal\_prec}{mu, Omega}

\subsubsection{Stan Functions}

\begin{description}
%
\fitemtwolines{real}{multi\_normal\_prec\_lpdf}{vectors \farg{y} \textbar\ vectors
  \farg{mu}}{matrix \farg{Omega}}{The log of the multivariate normal density of vector(s)
  \farg{y} given location vector(s) \farg{mu} and positive definite precision
  matrix \farg{Omega}}
%
\fitemtwolines{real}{multi\_normal\_prec\_lpdf}{vectors \farg{y} \textbar\ row\_vectors
  \farg{mu}}{matrix \farg{Omega}}{The log of the multivariate normal density of vector(s)
  \farg{y} given location row vector(s) \farg{mu} and positive definite precision
  matrix \farg{Omega}}
%
\fitemtwolines{real}{multi\_normal\_prec\_lpdf}{row\_vectors \farg{y} \textbar\ vectors
  \farg{mu}}{matrix \farg{Omega}}{The log of the multivariate normal density of row vector(s)
  \farg{y} given location vector(s) \farg{mu} and positive definite precision
  matrix \farg{Omega}}
%
\fitemtwolines{real}{multi\_normal\_prec\_lpdf}{row\_vectors \farg{y} \textbar\ row\_vectors
  \farg{mu}}{matrix \farg{Omega}}{The log of the multivariate normal density of row vector(s)
  \farg{y} given location row vector(s) \farg{mu} and positive definite precision
  matrix \farg{Omega}}
%
\end{description}



\section{Multivariate Normal Distribution, Cholesky Parameterization}\label{multi-normal-cholesky-fun.section}

\subsubsection{Probability Density Function}

If $K \in \nats$, $\mu \in \reals^K$, and $L \in \reals^{K \times K}$
is lower triangular and such that $LL^{\top}$ is positive definite,
then for $y \in \reals^K$,
\[
\distro{MultiNormalCholesky}(y|\mu,L)
=
\distro{MultiNormal}(y|\mu,LL^{\top}).
\]
If $L$ is lower triangular and $LL^{top}$ is a $K \times K$ positive
definite matrix, then $L_{k,k}$ must be strictly positive for $k \in
1{:}K$.  If an $L$ is provided that is not the Cholesky factor of a
positive-definite matrix, the probability functions will raise errors.

\pitem{y}{multi\_normal\_cholesky}{mu, L}

\subsubsection{Stan Functions}

\begin{description}
%
\fitemtwolines{real}{multi\_normal\_cholesky\_lpdf}{vectors \farg{y} \textbar\ vectors
  \farg{mu}}{matrix \farg{L}}{The log of the multivariate normal density of vector(s)
  \farg{y} given location vector(s) \farg{mu} and lower-triangular Cholesky
  factor of the covariance matrix \farg{L}}
%
\fitemtwolines{real}{multi\_normal\_cholesky\_lpdf}{vectors \farg{y} \textbar\ row\_vectors
  \farg{mu}}{matrix \farg{L}}{The log of the multivariate normal density of vector(s)
  \farg{y} given location row vector(s) \farg{mu} and lower-triangular Cholesky
  factor of the covariance matrix \farg{L}}
%
\fitemtwolines{real}{multi\_normal\_cholesky\_lpdf}{row\_vectors \farg{y} \textbar\ vectors
  \farg{mu}}{matrix \farg{L}}{The log of the multivariate normal density of row vector(s)
  \farg{y} given location vector(s) \farg{mu} and lower-triangular Cholesky
  factor of the covariance matrix \farg{L}}
%
\fitemtwolines{real}{multi\_normal\_cholesky\_lpdf}{row\_vectors \farg{y} \textbar\ row\_vectors
  \farg{mu}}{matrix \farg{L}}{The log of the multivariate normal density of row vector(s)
  \farg{y} given location row vector(s) \farg{mu} and lower-triangular Cholesky
  factor of the covariance matrix \farg{L}}
%
\end{description}
%
\begin{description}
\fitem{vector}{multi\_normal\_cholesky\_rng}{vector \farg{mu}, matrix
  \farg{L}}{Generate a multivariate normal variate with location
  \farg{mu} and lower-triangular Cholesky factor of the covariance
  matrix \farg{L}; may only be used in generated quantities block}
\end{description}


\section{Multivariate Gaussian Process Distribution}

\subsubsection{Probability Density Function}

If $K,N \in \nats$, $\Sigma \in \reals^{N \times N}$ is symmetric,
positive definite kernel matrix and $w \in \reals^{K}$ is a vector of positive
inverse scales, then for $y \in \reals^{K \times N}$,
\[
\distro{MultiGP}(y|\Sigma,w)
=
\prod_{i=1}^{K} \distro{MultiNormal}(y_i|0,w_i^{-1} \Sigma),
\]
where $y_i$ is the $i$th row of $y$.  This is used to efficiently handle
Gaussian Processes with multi-variate outputs where only the output dimensions
share a kernel function but vary based on their scale.  Note that this
function does not take into account the mean prediction.

\pitem{y}{multi\_gp}{Sigma, w}

\subsubsection{Stan Functions}

\begin{description}
%
\fitem{real}{multi\_gp\_lpdf}{matrix \farg{y} \textbar\ matrix \farg{Sigma},
  vector \farg{w}}{The log of the multivariate GP density of matrix
  \farg{y} given kernel matrix \farg{Sigma} and inverses scales
  \farg{w}}
%
\end{description}


\section{Multivariate Gaussian Process Distribution, Cholesky parameterization}

\subsubsection{Probability Density Function}

If $K,N \in \nats$, $L \in \reals^{N \times N}$ is lower triangular
and such that $LL^{\top}$ is positive definite kernel matrix (implying
$L_{n,n} > 0$ for $n \in 1{:}N$), and $w \in \reals^{K}$ is a vector
of positive inverse scales, then for $y \in \reals^{K \times N}$,
\[
\distro{MultiGPCholesky}(y \, | \ L,w)
=
\prod_{i=1}^{K} \distro{MultiNormal}(y_i|0,w_i^{-1} LL^{\top}),
\]
where $y_i$ is the $i$th row of $y$.  This is used to efficiently handle
Gaussian Processes with multi-variate outputs where only the output dimensions
share a kernel function but vary based on their scale.  If the model allows
parametrization in terms of Cholesky factor of the kernel matrix, this distribution
is also more efficient than $\distro{MultiGP}()$. Note that this
function does not take into account the mean prediction.

\pitem{y}{multi\_gp\_cholesky}{L, w}

\subsubsection{Stan Functions}

\begin{description}
%
\fitem{real}{multi\_gp\_cholesky\_lpdf}{matrix \farg{y} \textbar\ matrix \farg{L},
  vector \farg{w}}{The log of the multivariate GP density of matrix
  \farg{y} given lower-triangular Cholesky factor of the kernel matrix \farg{L} and inverses scales
  \farg{w}}
%
\end{description}


\section{Multivariate Student-$t$ Distribution}

\subsubsection{Probability Density Function}

If $K \in \nats$, $\nu \in \posreals$, $\mu \in \reals^K$, and $\Sigma
\in \reals^{K \times K}$ is symmetric and positive definite, then for
$y \in \reals^K$,
\[
\begin{array}{l}
\distro{MultiStudentT}(y|\nu,\mu,\Sigma)
\\[8pt]
\displaystyle
\hspace*{8pt}
=
\frac{1}{\pi^{K/2}}
\
\frac{1}{\nu^{K/2}}
\
\frac{\Gamma\!\left((\nu + K)/2\right)}
     {\Gamma(\nu/2)}
\
\frac{1}{\sqrt{\left| \Sigma \right|}}
\
\left(
1 + \frac{1}{\nu} \, \left(y - \mu\right)^{\top} \, \Sigma^{-1} \, \left(y - \mu\right)
\right)^{-(\nu + K)/2}
\! .
\end{array}
\]
\vspace*{4pt}

\pitem{y}{multi\_student\_t}{nu, mu, Sigma}


\subsubsection{Stan Functions}

\begin{description}
%
\fitemtwolines{real}{multi\_student\_t\_lpdf}{vectors \farg{y} \textbar\ real \farg{nu},
  vectors \farg{mu}}{matrix \farg{Sigma}}{The log of the multivariate Student-$t$
  density of vector(s) \farg{y} given degrees of freedom \farg{nu},
  location vector(s) \farg{mu}, and scale matrix \farg{Sigma}}
%
\fitemtwolines{real}{multi\_student\_t\_lpdf}{vectors \farg{y} \textbar\ real \farg{nu},
  row\_vectors \farg{mu}}{matrix \farg{Sigma}}{The log of the multivariate Student-$t$
  density of vector(s) \farg{y} given degrees of freedom \farg{nu},
  location row vector(s) \farg{mu}, and scale matrix \farg{Sigma}}
%
\fitemtwolines{real}{multi\_student\_t\_lpdf}{row\_vectors \farg{y} \textbar\ real \farg{nu},
  vectors \farg{mu}}{matrix \farg{Sigma}}{The log of the multivariate Student-$t$
  density of row vector(s) \farg{y} given degrees of freedom \farg{nu},
  location vector(s) \farg{mu}, and scale matrix \farg{Sigma}}
%
\fitemtwolines{real}{multi\_student\_t\_lpdf}{row\_vectors \farg{y} \textbar\ real \farg{nu},
  row\_vectors \farg{mu}}{matrix \farg{Sigma}}{The log of the multivariate Student-$t$
  density of row vector(s) \farg{y} given degrees of freedom \farg{nu},
  location row vector(s) \farg{mu}, and scale matrix \farg{Sigma}}
%
\end{description}
%
\begin{description}
\fitem{vector}{multi\_student\_t\_rng}{real \farg{nu}, vector \farg{mu}, matrix
  \farg{Sigma}}{Generate a multivariate Student-$t$ variate with degrees
  of freedom \farg{nu}, location \farg{mu}, and scale matrix \farg{Sigma};
may only be used in generated quantities block}
\end{description}


\section{Gaussian Dynamic Linear Models}

A Gaussian Dynamic Linear model is defined as follows,
For $t \in 1, \dots, T$,
\[
  \begin{aligned}[t]
    y_{t} &\sim N(F' \theta_{t}, V) \\
    \theta_{t} &\sim N(G \theta_{t - 1}, W) \\
    \theta_{0} &\sim N(m_{0}, C_{0})
  \end{aligned}
\]
where $y$ is $n \times T$ matrix where rows are variables and columns
are observations. These functions calculate the log-likelihood of the
observations marginalizing over the latent states ($p(y | F, G, V, W,
m_{0}, C_{0})$). This log-likelihood is a system that is calculated using
the Kalman Filter. If $V$ is diagonal, then a more efficient
algorithm which sequentially processes observations and avoids a
matrix inversions can be used \citep[Sec~6.4]{DurbinKoopman:2001}.

\pitem{y}{gaussian\_dlm\_obs}{F, G, V, W, m0, C0}

\subsubsection{Stan Functions}

The following two functions differ in the type of their \farg{V}, the
first taking a full observation covariance matrix \farg{V}\ and the
second a vector \farg{V}\ representing the diagonal of the observation
covariance matrix.  The sampling statement defined in the previous
section works with either type of observation \farg{V}.

\begin{description}
%
\fitemtwolines{real}{gaussian\_dlm\_obs\_lpdf}{matrix \farg{y} \textbar\ matrix \farg{F},
  matrix \farg{G}, matrix \farg{V}}{matrix \farg{W}, vector
  \farg{m0}, matrix \farg{C0}}{The log of the density of the
  Gaussian Dynamic Linear model with observation matrix \farg{y} in
  which rows are variables and columns are observations, design
  matrix \farg{F}, transition matrix \farg{G}, observation
  covariance matrix \farg{V}, system covariance matrix \farg{W}, and
  the initial state is distributed normal with mean \farg{m0} and
  covariance \farg{C0}.}
%
%
\fitemtwolines{real}{gaussian\_dlm\_obs\_lpdf}{matrix \farg{y} \textbar\ matrix \farg{F},
  matrix \farg{G}, vector \farg{V}}{matrix \farg{W}, vector \farg{m0},
  matrix \farg{C0}} {The log of the density of the Gaussian Dynamic
  Linear model with observation matrix \farg{y} in which rows are
  variables and columns are observations, design matrix \farg{F},
  transition matrix \farg{G}, observation covariance matrix with
  diagonal \farg{V}, system covariance matrix \farg{W}, and the
  initial state is distributed normal with mean \farg{m0} and
  covariance \farg{C0}.}
%
\end{description}


\chapter{Simplex Distributions}

\noindent
The simplex probabilities have support on the unit $K$-simplex for a
specified $K$.  A $K$-dimensional vector $\theta$ is a unit
$K$-simplex if $\theta_k \geq 0$ for $k \in \setlist{1,\ldots,K}$ and
$\sum_{k = 1}^K \theta_k = 1$.


\section{Dirichlet Distribution}

\subsubsection{Probability Density Function}

If $K \in \nats$ and $\alpha \in (\posreals)^{K}$, then for
$\theta \in \mbox{$K$-simplex}$,
\[
\distro{Dirichlet}(\theta|\alpha)
=
\frac{\Gamma \! \left( \sum_{k=1}^K \alpha_k \right)}
     {\prod_{k=1}^K \Gamma(\alpha_k)}
\
\prod_{k=1}^K \theta_k^{\alpha_k - 1}
.
\]

{\it Warning:}\ If any of the components of $\theta$ satisfies
$\theta_i = 0$ or $\theta_i = 1$, then the probability is 0 and the log
probability is $-\infty$.  Similarly, the distribution requires
strictly positive parameters, with $\alpha_i > 0$ for each $i$.


\pitem{theta}{dirichlet}{alpha}

\subsubsection{Stan Functions}

\begin{description}
  \fitem{real}{dirichlet\_lpdf}{vector \farg{theta} \textbar\ vector
    \farg{alpha}}{ The log of the Dirichlet density for simplex
    \farg{theta} given prior counts (plus one) \farg{alpha}}
\end{description}
%
\begin{description}
\fitem{vector}{dirichlet\_rng}{vector \farg{alpha}}{Generate a
  Dirichlet variate with prior counts (plus one) \farg{alpha};
may only be used in generated quantities block}
\end{description}


\chapter{Correlation Matrix Distributions}

\noindent
The correlation matrix distributions have support on the (Cholesky
factors of) correlation matrices.  A Cholesky factor $L$ for a $K
\times K$ correlation matrix $\Sigma$ of dimension $K$ has rows of unit
length so that the diagonal of $L L^{\top}$ is the unit $K$-vector. Even
though models are usually conceptualized in terms of correlation matrices,
it is better to operationalize them in terms of their Cholesky factors.
If you are interested in the posterior distribution of the correlations,
you can recover them in the generated quantities block via
%
\begin{stancode}
generated quantities {
  corr_matrix[K] Sigma;
  Sigma = multiply_lower_tri_self_transpose(L);
}
\end{stancode}
%
\section{LKJ Correlation Distribution}\label{lkj-correlation.section}

\subsubsection{Probability Density Function}

For $\eta > 0$, if $\Sigma$ a positive-definite, symmetric matrix with
unit diagonal (i.e., a correlation matrix), then
%
\[
\distro{LkjCorr}(\Sigma|\eta)
\propto \det \left( \Sigma \right)^{(\eta - 1)}.
\]
%
The expectation is the identity matrix for any positive value of the
shape parameter $\eta$, which can be interpreted like the shape parameter
of a symmetric beta distribution:
%
\begin{itemize}
\item if $\eta = 1$, then the density is uniform over correlation
  matrices of order $K$;
\item if $\eta > 1$, the identity matrix is the modal correlation
  matrix, with a sharper peak in the density at the identity matrix
  for larger $\eta$; and
\item for $0 < \eta < 1$, the density has a trough at the identity
  matrix.
\item if $\eta$ were an unknown parameter, the Jeffreys prior is
  proportional to $\sqrt{2\sum_{k=1}^{K-1}\left(
  \psi_1\left(\eta+\frac{K-k-1}{2}\right) -
  2\psi_1\left(2\eta+K-k-1 \right)\right)}$, where $\psi_1()$ is the
  trigamma function
\end{itemize}
%
See \citep{LewandowskiKurowickaJoe:2009} for definitions. However, it
is much better computationally to work directly with the Cholesky factor
of $\Sigma$, so this distribution should never be explicitly used in
practice.

\pitem{y}{lkj\_corr}{eta}

\subsubsection{Stan Functions}

\begin{description}
%
  \fitem{real}{lkj\_corr\_lpdf}{matrix \farg{y} \textbar\ real
    \farg{eta}}{The log of the LKJ density for the correlation matrix
    \farg{y} given nonnegative shape \farg{eta}. The only reason to
    use this density function is if you want the code to run slower
    and consume more memory with more risk of numerical errors.
    Use its Cholesky factor as described in the next section.}
%
\end{description}
\begin{description}
\fitem{matrix}{lkj\_corr\_rng}{int \farg{K}, real \farg{eta}}{Generate a
  LKJ random correlation matrix of order \farg{K} with shape \farg{eta};
  may only be used in generated quantities block}
\end{description}


\section{Cholesky LKJ Correlation Distribution}

Stan provides an implicit parameterization of the LKJ correlation matrix
density in terms of its Cholesky factor, which you should use rather
than the explicit parameterization in the previous section. For example,
if \code{L} is a Cholesky factor of a correlation matrix, then
%
\begin{stancode}
L ~ lkj_corr_cholesky(2.0);
# implies L * L' ~ lkj_corr(2.0);
\end{stancode}
%
Because Stan requires models to have support on all valid constrained
parameters, \code{L} will almost always
%
\footnote{It is possible to build up a valid \code{L} within Stan, but that
would then require Jacobian adjustments to imply the intended posterior.}
%
be a parameter declared with the type of a
Cholesky factor for a correlation matrix; for example,
%
\begin{stancode}
parameters {
  cholesky_factor_corr[K] L;
  # rather than corr_matrix[K] Sigma;
  // ...
\end{stancode}
%


\subsubsection{Probability Density Function}

For $\eta > 0$, if $L$ is a $K \times K$ lower-triangular Cholesky
factor of a symmetric positive-definite matrix with unit diagonal
(i.e., a correlation matrix), then
\[
\distro{LkjCholesky}(L|\eta)
\propto \left|J\right|\det(L L^\top)^{(\eta - 1)}
= \prod_{k=2}^K L_{kk}^{K-k+2\eta-2}.
\]
See the previous section for details on interpreting the shape
parameter $\eta$. Note that even if $\eta=1$, it is still essential to
evaluate the density function because the density of $L$ is not
constant, regardless of the value of $\eta$, even though the density of
$LL^\top$ is constant iff $\eta=1$.

A lower triangular $L$ is a Cholesky factor for a correlation matrix
if and only if $L_{k,k} > 0$ for $k \in 1{:}K$ and each row $L_k$ has
unit Euclidean length.

\pitem{L}{lkj\_corr\_cholesky}{eta}

\subsubsection{Stan Functions}

\begin{description}
%
  \fitem{real}{lkj\_corr\_cholesky\_lpdf}{matrix \farg{L} \textbar\ real
    \farg{eta}}{The log of the LKJ density for the lower-triangular
    Cholesky factor \farg{L} of a correlation matrix given shape
    \farg{eta}.}
%
\end{description}
\begin{description}
\fitem{matrix}{lkj\_corr\_cholesky\_rng}{int \farg{K}, real \farg{eta}}{
  Generate a random Cholesky factor of a correlation matrix of order
  \farg{K} that is distributed LKJ with shape \farg{eta}; may only be
  used in generated quantities block}
\end{description}




\chapter{Covariance Matrix Distributions}

\noindent
The covariance matrix distributions have support on symmetric,
positive-definite $K \times K$ matrices.


\section{Wishart Distribution}

\subsubsection{Probability Density Function}

If $K \in \nats$, $\nu \in (K-1,\infty)$, and $S \in \reals^{K \times K}$ is symmetric
and positive definite, then for symmetric and positive-definite $W \in
\reals^{K \times K}$,
\[
\distro{Wishart}(W|\nu,S)
=
\frac{1}{2^{\nu K / 2}}
\
\frac{1}{\Gamma_K \! \left( \frac{\nu}{2} \right)}
\
\left| S \right|^{-\nu/2}
\
\left| W \right|^{(\nu - K - 1)/2}
\
\exp \! \left(- \frac{1}{2} \ \mbox{tr}\left( S^{-1} W \right) \right)
\! ,
\]
%
where $\mbox{tr}()$ is the matrix trace function, and $\Gamma_K()$ is
the multivariate Gamma function,
\[
\Gamma_K(x) =
\frac{1}{\pi^{K(K-1)/4}}
\
\prod_{k=1}^K \Gamma \left( x + \frac{1 - k}{2} \right)
\!.
\]

\pitem{W}{wishart}{nu, Sigma}

\subsubsection{Stan Functions}

\begin{description}
%
\fitem{real}{wishart\_lpdf}{matrix \farg{W} \textbar\ real \farg{nu}, matrix
 \farg{Sigma}}{The log of the Wishart density for symmetric and positive-definite matrix
 \farg{W} given degrees of freedom \farg{nu} and symmetric and positive-definite scale matrix
 \farg{Sigma}}
%
\end{description}
%
\begin{description}
\fitem{matrix}{wishart\_rng}{real \farg{nu}, matrix \farg{Sigma}}{Generate a
  Wishart variate with degrees of freedom \farg{nu} and symmetric and positive-definite scale matrix
 \farg{Sigma}; may only be used in generated quantities block}
\end{description}


\section{Inverse Wishart Distribution}

\subsubsection{Probability Density Function}

If $K \in \nats$, $\nu \in (K-1,\infty)$, and $S \in \reals^{K \times
  K}$ is symmetric and positive definite, then for symmetric and
positive-definite $W \in \reals^{K \times K}$,
\[
\distro{InvWishart}(W|\nu,S)
=
\frac{1}{2^{\nu K / 2}}
\
\frac{1}{\Gamma_K \! \left( \frac{\nu}{2} \right)}
\
\left| S \right|^{\nu/2}
\
\left| W \right|^{-(\nu + K + 1)/2}
\
\exp \! \left(
- \frac{1}{2}
\
\mbox{tr}(SW^{-1})
\right)
\! .
\]

\pitem{W}{inv\_wishart}{nu, Sigma}

\subsubsection{Stan Functions}

\begin{description}
%
\fitem{real}{inv\_wishart\_lpdf}{matrix \farg{W} \textbar\ real \farg{nu}, matrix
 \farg{Sigma}}{The log of the inverse Wishart density for symmetric and positive-definite matrix
 \farg{W} given degrees of freedom \farg{nu} and symmetric and positive-definite scale matrix
 \farg{Sigma}}
%
\end{description}
%
\begin{description}
\fitem{matrix}{inv\_wishart\_rng}{real \farg{nu}, matrix
  \farg{Sigma}}{Generate an inverse Wishart variate with degrees of
freedom \farg{nu} and symmetric and positive-definite scale matrix
 \farg{Sigma}; may only be used in generated quantities block}
\end{description}





